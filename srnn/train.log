2025-04-20 15:22:27,799:INFO: Training begin
2025-04-20 15:45:33,376:INFO: Training begin
2025-04-20 16:11:42,523:INFO: Training begin
2025-04-20 16:36:56,315:INFO: Training begin
2025-04-20 16:43:58,145:INFO: Training begin
2025-04-20 16:53:59,919:INFO: Training begin
2025-04-20 16:57:22,394:INFO: Training begin
2025-04-20 16:57:54,838:INFO: Training begin
2025-04-20 16:59:10,992:INFO: Training begin
2025-04-20 17:37:19,545:INFO: Training begin
2025-04-20 17:40:15,237:INFO: Training begin
2025-04-20 17:44:16,281:INFO: Training begin
2025-04-20 17:54:13,337:INFO: Training begin
2025-04-20 18:04:53,880:INFO: Training begin
2025-04-20 18:08:05,639:INFO: Training begin
2025-04-20 19:02:28,347:INFO: Training begin
2025-04-20 19:12:42,886:INFO: Training begin
2025-04-20 20:05:29,110:INFO: Training begin
2025-04-20 20:11:27,699:INFO: Training begin
2025-04-20 20:12:39,788:INFO: Training begin
2025-04-20 20:13:30,661:INFO: Training begin
2025-04-20 21:51:52,333:INFO: Training begin
2025-04-20 21:56:03,516:INFO: Training begin
2025-04-20 22:17:55,199:INFO: Training begin
2025-04-20 22:27:10,895:INFO: Training begin
2025-04-20 22:31:01,270:INFO: Training begin
2025-04-20 22:31:10,084:INFO: 0/260 (epoch 0), train_loss = 3.469119071960, time/batch = 8.814153194427
2025-04-20 23:09:27,456:INFO: Training begin
2025-04-20 23:15:42,129:INFO: Training begin
2025-04-20 23:15:47,615:INFO: 0/260 (epoch 0), train_loss = 3.147367954254, time/batch = 5.485992908478
2025-04-20 23:15:51,085:INFO: 1/260 (epoch 0), train_loss = 3.460495948792, time/batch = 3.469722509384
2025-04-20 23:15:57,260:INFO: 2/260 (epoch 0), train_loss = 3.485008478165, time/batch = 6.174932241440
2025-04-20 23:22:03,396:INFO: Training begin
2025-04-20 23:22:05,646:INFO: 0/260 (epoch 0), train_loss = 3.398240566254, time/batch = 2.249922990799
2025-04-20 23:22:11,429:INFO: 1/260 (epoch 0), train_loss = 3.524659633636, time/batch = 5.782821893692
2025-04-20 23:22:14,461:INFO: 2/260 (epoch 0), train_loss = 3.451015472412, time/batch = 3.031846761703
2025-04-20 23:22:17,978:INFO: 3/260 (epoch 0), train_loss = 3.584505081177, time/batch = 3.517120838165
2025-04-20 23:22:26,420:INFO: 4/260 (epoch 0), train_loss = 3.720732450485, time/batch = 8.441762208939
2025-04-20 23:22:29,733:INFO: 5/260 (epoch 0), train_loss = 3.426286697388, time/batch = 3.313788175583
2025-04-20 23:22:34,640:INFO: 6/260 (epoch 0), train_loss = 3.159563302994, time/batch = 4.906948089600
2025-04-20 23:22:41,628:INFO: 7/260 (epoch 0), train_loss = 3.491360187531, time/batch = 6.988106489182
2025-04-20 23:22:49,663:INFO: 8/260 (epoch 0), train_loss = 3.714010000229, time/batch = 8.034530639648
2025-04-20 23:22:50,898:INFO: 9/260 (epoch 0), train_loss = 3.568511009216, time/batch = 1.234886646271
2025-04-20 23:22:58,714:INFO: 10/260 (epoch 0), train_loss = 3.442991971970, time/batch = 7.816084384918
2025-04-20 23:23:03,012:INFO: 11/260 (epoch 0), train_loss = 3.725634574890, time/batch = 4.298184871674
2025-04-20 23:23:06,607:INFO: 12/260 (epoch 0), train_loss = 3.580989837646, time/batch = 3.594757795334
2025-04-20 23:23:07,060:INFO: 13/260 (epoch 0), train_loss = 3.597532510757, time/batch = 0.453145503998
2025-04-20 23:23:12,984:INFO: 14/260 (epoch 0), train_loss = 3.297230243683, time/batch = 5.924166917801
2025-04-20 23:23:16,220:INFO: 15/260 (epoch 0), train_loss = 3.643875122070, time/batch = 3.235415697098
2025-04-20 23:23:19,705:INFO: 16/260 (epoch 0), train_loss = 3.602244853973, time/batch = 3.485439300537
2025-04-20 23:23:27,521:INFO: 17/260 (epoch 0), train_loss = 4.021059989929, time/batch = 7.815760374069
2025-04-20 23:23:31,115:INFO: 18/260 (epoch 0), train_loss = 3.515337705612, time/batch = 3.594182968140
2025-04-20 23:23:36,086:INFO: 19/260 (epoch 0), train_loss = 3.419544696808, time/batch = 4.970678806305
2025-04-20 23:23:43,119:INFO: 20/260 (epoch 0), train_loss = 3.232134342194, time/batch = 7.032924413681
2025-04-20 23:23:51,923:INFO: 21/260 (epoch 0), train_loss = 3.396184921265, time/batch = 8.804785251617
2025-04-20 23:23:53,002:INFO: 22/260 (epoch 0), train_loss = 3.584672927856, time/batch = 1.078618526459
2025-04-20 23:24:00,803:INFO: 23/260 (epoch 0), train_loss = 3.383709669113, time/batch = 7.800638675690
2025-04-20 23:24:05,038:INFO: 24/260 (epoch 0), train_loss = 3.826025724411, time/batch = 4.235485076904
2025-04-20 23:24:08,711:INFO: 25/260 (epoch 0), train_loss = 3.318852186203, time/batch = 3.673133611679
2025-04-20 23:24:09,164:INFO: 26/260 (epoch 1), train_loss = 3.720179557800, time/batch = 0.453149318695
2025-04-20 23:24:14,980:INFO: 27/260 (epoch 1), train_loss = 3.487056970596, time/batch = 5.815068006516
2025-04-20 23:24:18,169:INFO: 28/260 (epoch 1), train_loss = 3.362021207809, time/batch = 3.189019441605
2025-04-20 23:24:21,669:INFO: 29/260 (epoch 1), train_loss = 3.379715204239, time/batch = 3.500647783279
2025-04-20 23:24:30,043:INFO: 30/260 (epoch 1), train_loss = 3.680472850800, time/batch = 8.374329090118
2025-04-20 23:24:33,502:INFO: 31/260 (epoch 1), train_loss = 3.611576795578, time/batch = 3.458331584930
2025-04-20 23:24:38,494:INFO: 32/260 (epoch 1), train_loss = 3.337125062943, time/batch = 4.991958856583
2025-04-20 23:24:45,618:INFO: 33/260 (epoch 1), train_loss = 3.421911478043, time/batch = 7.123838901520
2025-04-20 23:24:53,871:INFO: 34/260 (epoch 1), train_loss = 3.413913488388, time/batch = 8.253758907318
2025-04-20 23:24:55,014:INFO: 35/260 (epoch 1), train_loss = 3.399890899658, time/batch = 1.142550468445
2025-04-20 23:25:02,892:INFO: 36/260 (epoch 1), train_loss = 3.289262294769, time/batch = 7.878113269806
2025-04-20 23:25:07,033:INFO: 37/260 (epoch 1), train_loss = 3.709721803665, time/batch = 4.141302347183
2025-04-20 23:25:10,535:INFO: 38/260 (epoch 1), train_loss = 3.522083997726, time/batch = 3.501244068146
2025-04-20 23:25:10,973:INFO: 39/260 (epoch 1), train_loss = 3.178425788879, time/batch = 0.437981128693
2025-04-20 23:25:16,818:INFO: 40/260 (epoch 1), train_loss = 3.477104187012, time/batch = 5.845446109772
2025-04-20 23:25:19,944:INFO: 41/260 (epoch 1), train_loss = 3.295605659485, time/batch = 3.125853300095
2025-04-20 23:25:23,431:INFO: 42/260 (epoch 1), train_loss = 3.506137609482, time/batch = 3.487167835236
2025-04-20 23:25:31,464:INFO: 43/260 (epoch 1), train_loss = 3.861554622650, time/batch = 8.033194303513
2025-04-20 23:25:34,903:INFO: 44/260 (epoch 1), train_loss = 3.452009677887, time/batch = 3.438581466675
2025-04-20 23:25:39,874:INFO: 45/260 (epoch 1), train_loss = 3.284877061844, time/batch = 4.971507072449
2025-04-20 23:25:46,814:INFO: 46/260 (epoch 1), train_loss = 3.389824151993, time/batch = 6.939435482025
2025-04-20 23:25:54,973:INFO: 47/260 (epoch 1), train_loss = 3.486978292465, time/batch = 8.158912658691
2025-04-20 23:25:55,989:INFO: 48/260 (epoch 1), train_loss = 3.352607250214, time/batch = 1.016559600830
2025-04-20 23:26:03,741:INFO: 49/260 (epoch 1), train_loss = 3.496228218079, time/batch = 7.736136674881
2025-04-20 23:26:07,914:INFO: 50/260 (epoch 1), train_loss = 3.730056762695, time/batch = 4.173403024673
2025-04-20 23:26:11,478:INFO: 51/260 (epoch 1), train_loss = 3.634690284729, time/batch = 3.563108682632
2025-04-20 23:26:11,915:INFO: 52/260 (epoch 2), train_loss = 3.231436252594, time/batch = 0.437522411346
2025-04-20 23:26:18,107:INFO: 53/260 (epoch 2), train_loss = 3.337038040161, time/batch = 6.191710233688
2025-04-20 23:26:21,248:INFO: 54/260 (epoch 2), train_loss = 3.531278133392, time/batch = 3.141263961792
2025-04-20 23:26:24,828:INFO: 55/260 (epoch 2), train_loss = 3.533344268799, time/batch = 3.579902648926
2025-04-20 23:26:32,611:INFO: 56/260 (epoch 2), train_loss = 3.711534500122, time/batch = 7.783453702927
2025-04-20 23:26:36,099:INFO: 57/260 (epoch 2), train_loss = 3.375373840332, time/batch = 3.487599134445
2025-04-20 23:26:41,179:INFO: 58/260 (epoch 2), train_loss = 3.498436927795, time/batch = 5.079772472382
2025-04-20 23:26:48,166:INFO: 59/260 (epoch 2), train_loss = 3.309699773788, time/batch = 6.987603187561
2025-04-20 23:26:56,294:INFO: 60/260 (epoch 2), train_loss = 3.346417188644, time/batch = 8.127895355225
2025-04-20 23:26:57,342:INFO: 61/260 (epoch 2), train_loss = 3.530750989914, time/batch = 1.047357320786
2025-04-20 23:27:05,613:INFO: 62/260 (epoch 2), train_loss = 3.337913513184, time/batch = 8.271904230118
2025-04-20 23:27:09,850:INFO: 63/260 (epoch 2), train_loss = 3.709057331085, time/batch = 4.236475944519
2025-04-20 23:27:13,490:INFO: 64/260 (epoch 2), train_loss = 3.705634355545, time/batch = 3.639539480209
2025-04-20 23:27:13,959:INFO: 65/260 (epoch 2), train_loss = 3.555251598358, time/batch = 0.469313621521
2025-04-20 23:27:20,014:INFO: 66/260 (epoch 2), train_loss = 3.211005210876, time/batch = 6.055511713028
2025-04-20 23:27:23,090:INFO: 67/260 (epoch 2), train_loss = 3.435805797577, time/batch = 3.075514316559
2025-04-20 23:27:26,606:INFO: 68/260 (epoch 2), train_loss = 3.131688833237, time/batch = 3.516267538071
2025-04-20 23:27:34,826:INFO: 69/260 (epoch 2), train_loss = 3.547712802887, time/batch = 8.220258474350
2025-04-20 23:27:38,172:INFO: 70/260 (epoch 2), train_loss = 3.096001625061, time/batch = 3.345711708069
2025-04-20 23:27:43,282:INFO: 71/260 (epoch 2), train_loss = 3.218592882156, time/batch = 5.110089540482
2025-04-20 23:27:50,269:INFO: 72/260 (epoch 2), train_loss = 3.383809328079, time/batch = 6.986540317535
2025-04-20 23:27:58,325:INFO: 73/260 (epoch 2), train_loss = 3.078164815903, time/batch = 8.055960655212
2025-04-20 23:27:59,403:INFO: 74/260 (epoch 2), train_loss = 3.624455451965, time/batch = 1.062997341156
2025-04-20 23:28:07,171:INFO: 75/260 (epoch 2), train_loss = 3.289483547211, time/batch = 7.767414569855
2025-04-20 23:28:11,359:INFO: 76/260 (epoch 2), train_loss = 3.712801933289, time/batch = 4.188624858856
2025-04-20 23:28:14,844:INFO: 77/260 (epoch 2), train_loss = 3.289272069931, time/batch = 3.484991073608
2025-04-20 23:28:15,266:INFO: 78/260 (epoch 3), train_loss = 3.382103204727, time/batch = 0.421895027161
2025-04-20 23:28:21,253:INFO: 79/260 (epoch 3), train_loss = 3.135665416718, time/batch = 5.986476421356
2025-04-20 23:28:24,472:INFO: 80/260 (epoch 3), train_loss = 3.252091169357, time/batch = 3.219331026077
2025-04-20 23:28:27,973:INFO: 81/260 (epoch 3), train_loss = 3.320931673050, time/batch = 3.501031637192
2025-04-20 23:28:35,866:INFO: 82/260 (epoch 3), train_loss = 3.812967777252, time/batch = 7.893028259277
2025-04-20 23:28:39,289:INFO: 83/260 (epoch 3), train_loss = 3.461770057678, time/batch = 3.423377990723
2025-04-20 23:28:44,245:INFO: 84/260 (epoch 3), train_loss = 3.272903203964, time/batch = 4.955389499664
2025-04-20 23:28:51,217:INFO: 85/260 (epoch 3), train_loss = 3.392201423645, time/batch = 6.972078084946
2025-04-20 23:28:59,284:INFO: 86/260 (epoch 3), train_loss = 3.411673545837, time/batch = 8.067347288132
2025-04-20 23:29:00,425:INFO: 87/260 (epoch 3), train_loss = 3.441770076752, time/batch = 1.140684843063
2025-04-20 23:29:08,553:INFO: 88/260 (epoch 3), train_loss = 3.496712207794, time/batch = 8.127817869186
2025-04-20 23:29:12,695:INFO: 89/260 (epoch 3), train_loss = 3.916587114334, time/batch = 4.141849279404
2025-04-20 23:29:16,290:INFO: 90/260 (epoch 3), train_loss = 3.487490177155, time/batch = 3.595075607300
2025-04-20 23:29:16,728:INFO: 91/260 (epoch 3), train_loss = 3.278384208679, time/batch = 0.437954425812
2025-04-20 23:29:22,557:INFO: 92/260 (epoch 3), train_loss = 3.300853490829, time/batch = 5.829797983170
2025-04-20 23:29:25,794:INFO: 93/260 (epoch 3), train_loss = 3.356293678284, time/batch = 3.236824750900
2025-04-20 23:29:29,296:INFO: 94/260 (epoch 3), train_loss = 3.545516967773, time/batch = 3.501327753067
2025-04-20 23:29:37,172:INFO: 95/260 (epoch 3), train_loss = 3.940379619598, time/batch = 7.876766443253
2025-04-20 23:29:40,454:INFO: 96/260 (epoch 3), train_loss = 3.460905313492, time/batch = 3.281874656677
2025-04-20 23:29:45,364:INFO: 97/260 (epoch 3), train_loss = 3.349572181702, time/batch = 4.909527540207
2025-04-20 23:29:52,478:INFO: 98/260 (epoch 3), train_loss = 3.328634023666, time/batch = 7.113959312439
2025-04-20 23:30:00,888:INFO: 99/260 (epoch 3), train_loss = 3.309301376343, time/batch = 8.410039901733
2025-04-20 23:30:01,998:INFO: 100/260 (epoch 3), train_loss = 3.394292354584, time/batch = 1.110126495361
2025-04-20 23:30:09,861:INFO: 101/260 (epoch 3), train_loss = 3.491575717926, time/batch = 7.863243103027
2025-04-20 23:30:14,144:INFO: 102/260 (epoch 3), train_loss = 3.784113407135, time/batch = 4.282729625702
2025-04-20 23:30:17,724:INFO: 103/260 (epoch 3), train_loss = 3.639561653137, time/batch = 3.580059051514
2025-04-20 23:30:18,177:INFO: 104/260 (epoch 4), train_loss = 3.637830734253, time/batch = 0.453148365021
2025-04-20 23:30:24,007:INFO: 105/260 (epoch 4), train_loss = 3.342799425125, time/batch = 5.830181837082
2025-04-20 23:30:27,119:INFO: 106/260 (epoch 4), train_loss = 3.407378196716, time/batch = 3.111810922623
2025-04-20 23:30:30,607:INFO: 107/260 (epoch 4), train_loss = 3.305225849152, time/batch = 3.487532377243
2025-04-20 23:30:38,423:INFO: 108/260 (epoch 4), train_loss = 3.568841695786, time/batch = 7.816222429276
2025-04-20 23:30:41,752:INFO: 109/260 (epoch 4), train_loss = 3.519562005997, time/batch = 3.329006433487
2025-04-20 23:30:46,691:INFO: 110/260 (epoch 4), train_loss = 3.230058908463, time/batch = 4.938992261887
2025-04-20 23:30:53,789:INFO: 111/260 (epoch 4), train_loss = 3.318882942200, time/batch = 7.097871065140
2025-04-20 23:31:02,231:INFO: 112/260 (epoch 4), train_loss = 3.150163650513, time/batch = 8.442366838455
2025-04-20 23:31:03,310:INFO: 113/260 (epoch 4), train_loss = 3.209420442581, time/batch = 1.078771352768
2025-04-20 23:31:11,297:INFO: 114/260 (epoch 4), train_loss = 3.249464988708, time/batch = 7.987650156021
2025-04-20 23:31:15,673:INFO: 115/260 (epoch 4), train_loss = 3.907343387604, time/batch = 4.375659465790
2025-04-20 23:31:19,177:INFO: 116/260 (epoch 4), train_loss = 3.717981100082, time/batch = 3.503746032715
2025-04-20 23:31:19,599:INFO: 117/260 (epoch 4), train_loss = 3.323102712631, time/batch = 0.421899318695
2025-04-20 23:31:25,632:INFO: 118/260 (epoch 4), train_loss = 3.529037952423, time/batch = 6.032930612564
2025-04-20 23:31:28,854:INFO: 119/260 (epoch 4), train_loss = 3.727734565735, time/batch = 3.222115993500
2025-04-20 23:31:32,371:INFO: 120/260 (epoch 4), train_loss = 3.526374340057, time/batch = 3.516696929932
2025-04-20 23:31:40,126:INFO: 121/260 (epoch 4), train_loss = 3.711179971695, time/batch = 7.755172967911
2025-04-20 23:31:43,613:INFO: 122/260 (epoch 4), train_loss = 3.554880380630, time/batch = 3.487072706223
2025-04-20 23:31:48,896:INFO: 123/260 (epoch 4), train_loss = 3.438301086426, time/batch = 5.282873392105
2025-04-20 23:31:55,867:INFO: 124/260 (epoch 4), train_loss = 3.487497568130, time/batch = 6.971746444702
2025-04-20 23:32:03,965:INFO: 125/260 (epoch 4), train_loss = 3.665704250336, time/batch = 8.098021268845
2025-04-20 23:32:05,091:INFO: 126/260 (epoch 4), train_loss = 3.241897344589, time/batch = 1.125510931015
2025-04-20 23:32:13,030:INFO: 127/260 (epoch 4), train_loss = 3.556832551956, time/batch = 7.939255237579
2025-04-20 23:32:17,251:INFO: 128/260 (epoch 4), train_loss = 3.698604345322, time/batch = 4.205147504807
2025-04-20 23:32:20,767:INFO: 129/260 (epoch 4), train_loss = 3.392788887024, time/batch = 3.516451358795
2025-04-20 23:32:21,221:INFO: 130/260 (epoch 5), train_loss = 3.285950899124, time/batch = 0.453148841858
2025-04-20 23:32:27,039:INFO: 131/260 (epoch 5), train_loss = 3.775073528290, time/batch = 5.817963838577
2025-04-20 23:32:30,308:INFO: 132/260 (epoch 5), train_loss = 3.550372600555, time/batch = 3.269521951675
2025-04-20 23:32:33,871:INFO: 133/260 (epoch 5), train_loss = 3.259253978729, time/batch = 3.563048362732
2025-04-20 23:32:41,889:INFO: 134/260 (epoch 5), train_loss = 4.056967258453, time/batch = 8.018265962601
2025-04-20 23:32:45,296:INFO: 135/260 (epoch 5), train_loss = 3.206743240356, time/batch = 3.407072544098
2025-04-20 23:32:50,331:INFO: 136/260 (epoch 5), train_loss = 3.496922969818, time/batch = 5.034415721893
2025-04-20 23:32:57,491:INFO: 137/260 (epoch 5), train_loss = 3.366679191589, time/batch = 7.160138368607
2025-04-20 23:33:05,727:INFO: 138/260 (epoch 5), train_loss = 3.359590530396, time/batch = 8.236119747162
2025-04-20 23:33:06,853:INFO: 139/260 (epoch 5), train_loss = 3.399075746536, time/batch = 1.125528335571
2025-04-20 23:33:14,857:INFO: 140/260 (epoch 5), train_loss = 3.411252498627, time/batch = 8.004487991333
2025-04-20 23:33:19,124:INFO: 141/260 (epoch 5), train_loss = 3.615236759186, time/batch = 4.267158031464
2025-04-20 23:33:22,703:INFO: 142/260 (epoch 5), train_loss = 3.362900733948, time/batch = 3.578818798065
2025-04-20 23:33:23,125:INFO: 143/260 (epoch 5), train_loss = 3.192198038101, time/batch = 0.422231435776
2025-04-20 23:33:29,381:INFO: 144/260 (epoch 5), train_loss = 3.470721721649, time/batch = 6.255633354187
2025-04-20 23:33:32,694:INFO: 145/260 (epoch 5), train_loss = 3.532745361328, time/batch = 3.313110351562
2025-04-20 23:33:36,539:INFO: 146/260 (epoch 5), train_loss = 3.481348037720, time/batch = 3.844827651978
2025-04-20 23:33:44,760:INFO: 147/260 (epoch 5), train_loss = 3.885725498199, time/batch = 8.220956325531
2025-04-20 23:33:48,152:INFO: 148/260 (epoch 5), train_loss = 3.416725158691, time/batch = 3.391691207886
2025-04-20 23:33:53,278:INFO: 149/260 (epoch 5), train_loss = 3.171985626221, time/batch = 5.126171112061
2025-04-20 23:34:00,434:INFO: 150/260 (epoch 5), train_loss = 3.595472812653, time/batch = 7.155985832214
2025-04-20 23:34:08,889:INFO: 151/260 (epoch 5), train_loss = 3.469581604004, time/batch = 8.455560684204
2025-04-20 23:34:09,967:INFO: 152/260 (epoch 5), train_loss = 3.432794570923, time/batch = 1.078181266785
2025-04-20 23:34:17,847:INFO: 153/260 (epoch 5), train_loss = 3.274601221085, time/batch = 7.879853963852
2025-04-20 23:34:22,114:INFO: 154/260 (epoch 5), train_loss = 3.704158306122, time/batch = 4.266340732574
2025-04-20 23:34:25,695:INFO: 155/260 (epoch 5), train_loss = 3.432506084442, time/batch = 3.580877304077
2025-04-20 23:34:26,148:INFO: 156/260 (epoch 6), train_loss = 3.467691421509, time/batch = 0.453603982925
2025-04-20 23:34:32,150:INFO: 157/260 (epoch 6), train_loss = 3.483542442322, time/batch = 6.001664161682
2025-04-20 23:34:35,308:INFO: 158/260 (epoch 6), train_loss = 3.424109220505, time/batch = 3.157922506332
2025-04-20 23:34:38,871:INFO: 159/260 (epoch 6), train_loss = 3.525422334671, time/batch = 3.563617944717
2025-04-20 23:34:46,923:INFO: 160/260 (epoch 6), train_loss = 3.756407976151, time/batch = 8.051176786423
2025-04-20 23:34:50,315:INFO: 161/260 (epoch 6), train_loss = 3.367669343948, time/batch = 3.392779111862
2025-04-20 23:34:55,397:INFO: 162/260 (epoch 6), train_loss = 3.397696495056, time/batch = 5.082073450089
2025-04-20 23:35:02,494:INFO: 163/260 (epoch 6), train_loss = 3.215630054474, time/batch = 7.096331834793
2025-04-20 23:35:10,700:INFO: 164/260 (epoch 6), train_loss = 3.579675197601, time/batch = 8.206780910492
2025-04-20 23:35:11,779:INFO: 165/260 (epoch 6), train_loss = 3.420760631561, time/batch = 1.078624725342
2025-04-20 23:35:19,906:INFO: 166/260 (epoch 6), train_loss = 3.419967889786, time/batch = 8.127218008041
2025-04-20 23:35:24,128:INFO: 167/260 (epoch 6), train_loss = 3.543005228043, time/batch = 4.221524000168
2025-04-20 23:35:27,677:INFO: 168/260 (epoch 6), train_loss = 3.310300350189, time/batch = 3.549078226089
2025-04-20 23:35:28,130:INFO: 169/260 (epoch 6), train_loss = 3.255530357361, time/batch = 0.453148365021
2025-04-20 23:35:34,087:INFO: 170/260 (epoch 6), train_loss = 3.407121658325, time/batch = 5.956453323364
2025-04-20 23:35:37,322:INFO: 171/260 (epoch 6), train_loss = 3.542739391327, time/batch = 3.235940456390
2025-04-20 23:35:40,949:INFO: 172/260 (epoch 6), train_loss = 3.527828216553, time/batch = 3.626083135605
2025-04-20 23:35:48,966:INFO: 173/260 (epoch 6), train_loss = 3.817974090576, time/batch = 8.017197608948
2025-04-20 23:35:52,419:INFO: 174/260 (epoch 6), train_loss = 3.337559700012, time/batch = 3.453738212585
2025-04-20 23:35:57,438:INFO: 175/260 (epoch 6), train_loss = 3.279762983322, time/batch = 5.018374681473
2025-04-20 23:36:04,627:INFO: 176/260 (epoch 6), train_loss = 3.540534019470, time/batch = 7.189204692841
2025-04-20 23:36:12,834:INFO: 177/260 (epoch 6), train_loss = 3.443634986877, time/batch = 8.207250356674
2025-04-20 23:36:13,991:INFO: 178/260 (epoch 6), train_loss = 3.344883203506, time/batch = 1.156759738922
2025-04-20 23:36:22,228:INFO: 179/260 (epoch 6), train_loss = 3.232835531235, time/batch = 8.237295866013
2025-04-20 23:36:26,417:INFO: 180/260 (epoch 6), train_loss = 3.945647239685, time/batch = 4.188633441925
2025-04-20 23:36:30,012:INFO: 181/260 (epoch 6), train_loss = 3.437886714935, time/batch = 3.595008373260
2025-04-20 23:36:30,496:INFO: 182/260 (epoch 7), train_loss = 3.380276679993, time/batch = 0.484400749207
2025-04-20 23:36:36,451:INFO: 183/260 (epoch 7), train_loss = 3.491692543030, time/batch = 5.939130544662
2025-04-20 23:36:40,077:INFO: 184/260 (epoch 7), train_loss = 3.449894428253, time/batch = 3.626077651978
2025-04-20 23:36:43,734:INFO: 185/260 (epoch 7), train_loss = 3.578509330750, time/batch = 3.656881809235
2025-04-20 23:36:51,800:INFO: 186/260 (epoch 7), train_loss = 3.734440088272, time/batch = 8.066260814667
2025-04-20 23:36:55,207:INFO: 187/260 (epoch 7), train_loss = 3.668997287750, time/batch = 3.406755447388
2025-04-20 23:37:00,461:INFO: 188/260 (epoch 7), train_loss = 3.268455982208, time/batch = 5.254170179367
2025-04-20 23:37:07,527:INFO: 189/260 (epoch 7), train_loss = 3.507613420486, time/batch = 7.065895080566
2025-04-20 23:37:15,703:INFO: 190/260 (epoch 7), train_loss = 3.373302936554, time/batch = 8.175802469254
2025-04-20 23:37:16,876:INFO: 191/260 (epoch 7), train_loss = 3.761046886444, time/batch = 1.172584772110
2025-04-20 23:37:24,909:INFO: 192/260 (epoch 7), train_loss = 3.548218250275, time/batch = 8.032909393311
2025-04-20 23:37:29,144:INFO: 193/260 (epoch 7), train_loss = 3.550679206848, time/batch = 4.235927820206
2025-04-20 23:37:32,692:INFO: 194/260 (epoch 7), train_loss = 3.583691596985, time/batch = 3.547487020493
2025-04-20 23:37:33,145:INFO: 195/260 (epoch 7), train_loss = 3.741215944290, time/batch = 0.453149795532
2025-04-20 23:37:39,022:INFO: 196/260 (epoch 7), train_loss = 3.220739603043, time/batch = 5.877070903778
2025-04-20 23:37:42,133:INFO: 197/260 (epoch 7), train_loss = 3.424632072449, time/batch = 3.111100435257
2025-04-20 23:37:45,870:INFO: 198/260 (epoch 7), train_loss = 3.570137977600, time/batch = 3.737102985382
2025-04-20 23:37:53,826:INFO: 199/260 (epoch 7), train_loss = 3.830155849457, time/batch = 7.955536842346
2025-04-20 23:37:57,329:INFO: 200/260 (epoch 7), train_loss = 3.316633224487, time/batch = 3.502786159515
2025-04-20 23:38:02,642:INFO: 201/260 (epoch 7), train_loss = 3.612038135529, time/batch = 5.298058032990
2025-04-20 23:38:09,738:INFO: 202/260 (epoch 7), train_loss = 3.330011844635, time/batch = 7.095443487167
2025-04-20 23:38:18,069:INFO: 203/260 (epoch 7), train_loss = 3.330888509750, time/batch = 8.330791950226
2025-04-20 23:38:19,162:INFO: 204/260 (epoch 7), train_loss = 3.414851188660, time/batch = 1.093806505203
2025-04-20 23:38:27,135:INFO: 205/260 (epoch 7), train_loss = 3.505842447281, time/batch = 7.972147941589
2025-04-20 23:38:31,338:INFO: 206/260 (epoch 7), train_loss = 4.109552383423, time/batch = 4.203792095184
2025-04-20 23:38:35,043:INFO: 207/260 (epoch 7), train_loss = 3.232611656189, time/batch = 3.688565492630
2025-04-20 23:38:35,480:INFO: 208/260 (epoch 8), train_loss = 3.495116472244, time/batch = 0.437522888184
2025-04-20 23:38:41,467:INFO: 209/260 (epoch 8), train_loss = 3.471583366394, time/batch = 5.970860958099
2025-04-20 23:38:44,795:INFO: 210/260 (epoch 8), train_loss = 3.557412147522, time/batch = 3.328791379929
2025-04-20 23:38:48,363:INFO: 211/260 (epoch 8), train_loss = 3.579991340637, time/batch = 3.567217350006
2025-04-20 23:38:56,303:INFO: 212/260 (epoch 8), train_loss = 3.979894638062, time/batch = 7.940351486206
2025-04-20 23:38:59,742:INFO: 213/260 (epoch 8), train_loss = 3.516116857529, time/batch = 3.439048290253
2025-04-20 23:39:04,774:INFO: 214/260 (epoch 8), train_loss = 3.724429607391, time/batch = 5.031954288483
2025-04-20 23:39:12,046:INFO: 215/260 (epoch 8), train_loss = 3.326421022415, time/batch = 7.272211551666
2025-04-20 23:39:20,252:INFO: 216/260 (epoch 8), train_loss = 3.338043689728, time/batch = 8.205827713013
2025-04-20 23:39:21,377:INFO: 217/260 (epoch 8), train_loss = 3.409019708633, time/batch = 1.125058889389
2025-04-20 23:39:29,350:INFO: 218/260 (epoch 8), train_loss = 3.309757471085, time/batch = 7.973091840744
2025-04-20 23:39:33,663:INFO: 219/260 (epoch 8), train_loss = 3.614522218704, time/batch = 4.313171386719
2025-04-20 23:39:37,227:INFO: 220/260 (epoch 8), train_loss = 3.248589038849, time/batch = 3.564059257507
2025-04-20 23:39:37,665:INFO: 221/260 (epoch 8), train_loss = 3.403172492981, time/batch = 0.437523365021
2025-04-20 23:39:43,541:INFO: 222/260 (epoch 8), train_loss = 3.502282619476, time/batch = 5.876396179199
2025-04-20 23:39:46,807:INFO: 223/260 (epoch 8), train_loss = 3.358479738235, time/batch = 3.265995979309
2025-04-20 23:39:50,528:INFO: 224/260 (epoch 8), train_loss = 3.439502716064, time/batch = 3.720319032669
2025-04-20 23:39:58,502:INFO: 225/260 (epoch 8), train_loss = 3.479798316956, time/batch = 7.973981142044
2025-04-20 23:40:01,956:INFO: 226/260 (epoch 8), train_loss = 3.503908395767, time/batch = 3.454178333282
2025-04-20 23:40:07,160:INFO: 227/260 (epoch 8), train_loss = 3.294577598572, time/batch = 5.204329729080
2025-04-20 23:40:14,586:INFO: 228/260 (epoch 8), train_loss = 3.230862379074, time/batch = 7.425770282745
2025-04-20 23:40:22,791:INFO: 229/260 (epoch 8), train_loss = 3.157377958298, time/batch = 8.205372333527
2025-04-20 23:40:24,010:INFO: 230/260 (epoch 8), train_loss = 3.455124378204, time/batch = 1.219236612320
2025-04-20 23:40:31,921:INFO: 231/260 (epoch 8), train_loss = 3.419205427170, time/batch = 7.910625219345
2025-04-20 23:40:36,235:INFO: 232/260 (epoch 8), train_loss = 3.414051294327, time/batch = 4.313573122025
2025-04-20 23:40:39,956:INFO: 233/260 (epoch 8), train_loss = 3.443604946136, time/batch = 3.720945119858
2025-04-20 23:40:40,409:INFO: 234/260 (epoch 9), train_loss = 3.333063125610, time/batch = 0.453148603439
2025-04-20 23:40:46,490:INFO: 235/260 (epoch 9), train_loss = 3.583272933960, time/batch = 6.081242084503
2025-04-20 23:40:49,711:INFO: 236/260 (epoch 9), train_loss = 3.288961887360, time/batch = 3.221132278442
2025-04-20 23:40:53,275:INFO: 237/260 (epoch 9), train_loss = 3.353322982788, time/batch = 3.563533544540
2025-04-20 23:41:01,278:INFO: 238/260 (epoch 9), train_loss = 3.863012552261, time/batch = 8.002892732620
2025-04-20 23:41:04,809:INFO: 239/260 (epoch 9), train_loss = 3.355383634567, time/batch = 3.531869649887
2025-04-20 23:41:09,842:INFO: 240/260 (epoch 9), train_loss = 3.333632469177, time/batch = 5.033019542694
2025-04-20 23:41:17,533:INFO: 241/260 (epoch 9), train_loss = 3.556209564209, time/batch = 7.690096616745
2025-04-20 23:41:25,926:INFO: 242/260 (epoch 9), train_loss = 3.168683767319, time/batch = 8.393980741501
2025-04-20 23:41:27,083:INFO: 243/260 (epoch 9), train_loss = 3.488626956940, time/batch = 1.156747579575
2025-04-20 23:41:35,445:INFO: 244/260 (epoch 9), train_loss = 3.348864316940, time/batch = 8.361488342285
2025-04-20 23:41:39,696:INFO: 245/260 (epoch 9), train_loss = 3.797671794891, time/batch = 4.251344680786
2025-04-20 23:41:43,322:INFO: 246/260 (epoch 9), train_loss = 3.246496677399, time/batch = 3.625647306442
2025-04-20 23:41:43,775:INFO: 247/260 (epoch 9), train_loss = 3.487063407898, time/batch = 0.453150749207
2025-04-20 23:41:49,792:INFO: 248/260 (epoch 9), train_loss = 3.264375686646, time/batch = 6.017090082169
2025-04-20 23:41:53,074:INFO: 249/260 (epoch 9), train_loss = 3.394599437714, time/batch = 3.282341957092
2025-04-20 23:41:56,717:INFO: 250/260 (epoch 9), train_loss = 3.572586297989, time/batch = 3.642943620682
2025-04-20 23:42:04,828:INFO: 251/260 (epoch 9), train_loss = 3.703595399857, time/batch = 8.111167907715
2025-04-20 23:42:08,314:INFO: 252/260 (epoch 9), train_loss = 3.253256320953, time/batch = 3.485720396042
2025-04-20 23:42:13,300:INFO: 253/260 (epoch 9), train_loss = 3.596476078033, time/batch = 4.986204147339
2025-04-20 23:42:20,834:INFO: 254/260 (epoch 9), train_loss = 3.557946681976, time/batch = 7.533855199814
2025-04-20 23:42:29,571:INFO: 255/260 (epoch 9), train_loss = 3.565441131592, time/batch = 8.736574172974
2025-04-20 23:42:30,711:INFO: 256/260 (epoch 9), train_loss = 3.445384979248, time/batch = 1.140689611435
2025-04-20 23:42:38,995:INFO: 257/260 (epoch 9), train_loss = 3.578090667725, time/batch = 8.283887624741
2025-04-20 23:42:43,232:INFO: 258/260 (epoch 9), train_loss = 3.728122711182, time/batch = 4.236774921417
2025-04-20 23:42:46,813:INFO: 259/260 (epoch 9), train_loss = 3.312696933746, time/batch = 3.581067562103
2025-04-21 00:24:13,724:INFO: Training begin
2025-04-21 00:24:17,616:INFO: 0/260 (epoch 0), train_loss = 3.378241300583, time/batch = 3.892301082611
2025-04-21 00:24:18,007:INFO: 1/260 (epoch 0), train_loss = 3.246454238892, time/batch = 0.391174316406
2025-04-21 00:24:21,571:INFO: 2/260 (epoch 0), train_loss = 3.142022848129, time/batch = 3.563637971878
2025-04-21 00:24:25,775:INFO: 3/260 (epoch 0), train_loss = 3.992100715637, time/batch = 4.203905582428
2025-04-21 00:24:28,824:INFO: 4/260 (epoch 0), train_loss = 2.968155145645, time/batch = 3.048705101013
2025-04-21 00:24:36,765:INFO: 5/260 (epoch 0), train_loss = 2.915205240250, time/batch = 7.941009283066
2025-04-21 00:24:44,565:INFO: 6/260 (epoch 0), train_loss = 2.861881971359, time/batch = 7.799931049347
2025-04-21 00:24:49,472:INFO: 7/260 (epoch 0), train_loss = 2.781030178070, time/batch = 4.907584190369
2025-04-21 00:24:57,526:INFO: 8/260 (epoch 0), train_loss = 3.455403804779, time/batch = 8.053276062012
2025-04-21 00:25:02,262:INFO: 9/260 (epoch 0), train_loss = 2.620890378952, time/batch = 4.736014127731
2025-04-21 00:25:10,310:INFO: 10/260 (epoch 0), train_loss = 2.536452293396, time/batch = 8.048748970032
2025-04-21 00:25:11,373:INFO: 11/260 (epoch 0), train_loss = 2.441118240356, time/batch = 1.063032150269
2025-04-21 00:25:17,251:INFO: 12/260 (epoch 0), train_loss = 2.266427755356, time/batch = 5.877976655960
2025-04-21 00:25:20,643:INFO: 13/260 (epoch 0), train_loss = 2.088899135590, time/batch = 3.391789674759
2025-04-21 00:25:21,049:INFO: 14/260 (epoch 0), train_loss = 1.924546003342, time/batch = 0.406276941299
2025-04-21 00:25:24,534:INFO: 15/260 (epoch 0), train_loss = 1.630737781525, time/batch = 3.485087633133
2025-04-21 00:25:28,833:INFO: 16/260 (epoch 0), train_loss = 8.674264907837, time/batch = 4.298084974289
2025-04-21 00:25:31,912:INFO: 17/260 (epoch 0), train_loss = 1.160166978836, time/batch = 3.079240798950
2025-04-21 00:25:39,978:INFO: 18/260 (epoch 0), train_loss = 1.147776842117, time/batch = 8.066033363342
2025-04-21 00:25:47,121:INFO: 19/260 (epoch 0), train_loss = 1.108423471451, time/batch = 7.142944097519
2025-04-21 00:25:52,185:INFO: 20/260 (epoch 0), train_loss = 1.026175260544, time/batch = 5.063753366470
2025-04-21 00:26:00,126:INFO: 21/260 (epoch 0), train_loss = 3.287651062012, time/batch = 7.941552877426
2025-04-21 00:26:03,767:INFO: 22/260 (epoch 0), train_loss = 1.063524007797, time/batch = 3.641304254532
2025-04-21 00:26:12,020:INFO: 23/260 (epoch 0), train_loss = 0.740941405296, time/batch = 8.252691268921
2025-04-21 00:26:13,255:INFO: 24/260 (epoch 0), train_loss = 0.637222647667, time/batch = 1.234462976456
2025-04-21 00:26:19,539:INFO: 25/260 (epoch 0), train_loss = 0.689547240734, time/batch = 6.284170150757
2025-04-21 00:26:19,539:INFO: (epoch 0), loss = 2.453
2025-04-21 00:26:19,539:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:26:19,539:INFO: Saving model
2025-04-21 00:26:22,868:INFO: 26/260 (epoch 1), train_loss = 0.639357268810, time/batch = 3.298058509827
2025-04-21 00:26:23,274:INFO: 27/260 (epoch 1), train_loss = 0.536410748959, time/batch = 0.406295537949
2025-04-21 00:26:27,745:INFO: 28/260 (epoch 1), train_loss = 0.365876555443, time/batch = 4.470380783081
2025-04-21 00:26:32,044:INFO: 29/260 (epoch 1), train_loss = 18.740108489990, time/batch = 4.283336162567
2025-04-21 00:26:35,216:INFO: 30/260 (epoch 1), train_loss = 0.644914269447, time/batch = 3.172571420670
2025-04-21 00:26:43,391:INFO: 31/260 (epoch 1), train_loss = 0.726918756962, time/batch = 8.174298048019
2025-04-21 00:26:50,940:INFO: 32/260 (epoch 1), train_loss = 0.706277370453, time/batch = 7.549952507019
2025-04-21 00:26:56,005:INFO: 33/260 (epoch 1), train_loss = 0.533437132835, time/batch = 5.065013170242
2025-04-21 00:27:04,899:INFO: 34/260 (epoch 1), train_loss = 9.838895797729, time/batch = 8.893018722534
2025-04-21 00:27:08,447:INFO: 35/260 (epoch 1), train_loss = -0.176876932383, time/batch = 3.547998189926
2025-04-21 00:27:16,810:INFO: 36/260 (epoch 1), train_loss = 0.033325158060, time/batch = 8.363056659698
2025-04-21 00:27:17,841:INFO: 37/260 (epoch 1), train_loss = -0.140077978373, time/batch = 1.031847953796
2025-04-21 00:27:24,437:INFO: 38/260 (epoch 1), train_loss = -0.226525887847, time/batch = 6.595680952072
2025-04-21 00:27:27,828:INFO: 39/260 (epoch 1), train_loss = -0.114416390657, time/batch = 3.391331672668
2025-04-21 00:27:28,235:INFO: 40/260 (epoch 1), train_loss = -0.100252851844, time/batch = 0.406256437302
2025-04-21 00:27:31,782:INFO: 41/260 (epoch 1), train_loss = -0.169686943293, time/batch = 3.547708749771
2025-04-21 00:27:36,010:INFO: 42/260 (epoch 1), train_loss = 37.901268005371, time/batch = 4.227982759476
2025-04-21 00:27:39,711:INFO: 43/260 (epoch 1), train_loss = -0.459835857153, time/batch = 3.700208425522
2025-04-21 00:27:47,984:INFO: 44/260 (epoch 1), train_loss = -0.489337623119, time/batch = 8.273189067841
2025-04-21 00:27:55,476:INFO: 45/260 (epoch 1), train_loss = -0.603467702866, time/batch = 7.491799116135
2025-04-21 00:28:00,699:INFO: 46/260 (epoch 1), train_loss = -0.757330715656, time/batch = 5.223357677460
2025-04-21 00:28:08,895:INFO: 47/260 (epoch 1), train_loss = 13.191846847534, time/batch = 8.196391582489
2025-04-21 00:28:13,082:INFO: 48/260 (epoch 1), train_loss = -0.301689475775, time/batch = 4.186430454254
2025-04-21 00:28:21,398:INFO: 49/260 (epoch 1), train_loss = -1.008151412010, time/batch = 8.315689325333
2025-04-21 00:28:22,429:INFO: 50/260 (epoch 1), train_loss = -1.067354917526, time/batch = 1.031081438065
2025-04-21 00:28:28,291:INFO: 51/260 (epoch 1), train_loss = -0.418100535870, time/batch = 5.861896276474
2025-04-21 00:28:28,291:INFO: (epoch 1), loss = 2.993
2025-04-21 00:28:28,291:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:28:28,291:INFO: Saving model
2025-04-21 00:28:31,981:INFO: 52/260 (epoch 2), train_loss = -0.455267429352, time/batch = 3.658647775650
2025-04-21 00:28:32,387:INFO: 53/260 (epoch 2), train_loss = -0.795953512192, time/batch = 0.406274795532
2025-04-21 00:28:36,108:INFO: 54/260 (epoch 2), train_loss = -1.154859423637, time/batch = 3.721090078354
2025-04-21 00:28:40,470:INFO: 55/260 (epoch 2), train_loss = 46.128543853760, time/batch = 4.362295150757
2025-04-21 00:28:44,222:INFO: 56/260 (epoch 2), train_loss = -0.466302990913, time/batch = 3.751456499100
2025-04-21 00:28:53,604:INFO: 57/260 (epoch 2), train_loss = -0.141231074929, time/batch = 9.381790399551
2025-04-21 00:29:00,767:INFO: 58/260 (epoch 2), train_loss = 0.079018816352, time/batch = 7.163401365280
2025-04-21 00:29:05,831:INFO: 59/260 (epoch 2), train_loss = -0.196459457278, time/batch = 5.064122438431
2025-04-21 00:29:14,945:INFO: 60/260 (epoch 2), train_loss = 36.404197692871, time/batch = 9.113609790802
2025-04-21 00:29:18,556:INFO: 61/260 (epoch 2), train_loss = -1.686186194420, time/batch = 3.610883474350
2025-04-21 00:29:26,842:INFO: 62/260 (epoch 2), train_loss = -0.837099313736, time/batch = 8.286627054214
2025-04-21 00:29:27,874:INFO: 63/260 (epoch 2), train_loss = -1.221613168716, time/batch = 1.031425714493
2025-04-21 00:29:33,677:INFO: 64/260 (epoch 2), train_loss = -1.630607604980, time/batch = 5.803535699844
2025-04-21 00:29:37,101:INFO: 65/260 (epoch 2), train_loss = -1.259207606316, time/batch = 3.423576354980
2025-04-21 00:29:37,507:INFO: 66/260 (epoch 2), train_loss = -1.179478526115, time/batch = 0.406432628632
2025-04-21 00:29:41,103:INFO: 67/260 (epoch 2), train_loss = -1.319400548935, time/batch = 3.595462322235
2025-04-21 00:29:45,510:INFO: 68/260 (epoch 2), train_loss = 46.259143829346, time/batch = 4.407012701035
2025-04-21 00:29:48,886:INFO: 69/260 (epoch 2), train_loss = -1.721810340881, time/batch = 3.375881433487
2025-04-21 00:29:56,797:INFO: 70/260 (epoch 2), train_loss = -1.795023322105, time/batch = 7.895254135132
2025-04-21 00:30:04,112:INFO: 71/260 (epoch 2), train_loss = -1.946920633316, time/batch = 7.315565586090
2025-04-21 00:30:09,601:INFO: 72/260 (epoch 2), train_loss = -2.217372655869, time/batch = 5.488537073135
2025-04-21 00:30:18,603:INFO: 73/260 (epoch 2), train_loss = 45.903179168701, time/batch = 9.002596855164
2025-04-21 00:30:22,277:INFO: 74/260 (epoch 2), train_loss = 0.056988455355, time/batch = 3.673345088959
2025-04-21 00:30:30,530:INFO: 75/260 (epoch 2), train_loss = -2.189232110977, time/batch = 8.253001213074
2025-04-21 00:30:31,561:INFO: 76/260 (epoch 2), train_loss = -2.367899179459, time/batch = 1.031450748444
2025-04-21 00:30:37,877:INFO: 77/260 (epoch 2), train_loss = -0.733386397362, time/batch = 6.315421342850
2025-04-21 00:30:37,877:INFO: (epoch 2), loss = 5.751
2025-04-21 00:30:37,877:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:30:37,877:INFO: Saving model
2025-04-21 00:30:41,394:INFO: 78/260 (epoch 3), train_loss = -0.806114077568, time/batch = 3.486072301865
2025-04-21 00:30:41,800:INFO: 79/260 (epoch 3), train_loss = -0.877330660820, time/batch = 0.390649795532
2025-04-21 00:30:45,332:INFO: 80/260 (epoch 3), train_loss = -0.996160209179, time/batch = 3.531968832016
2025-04-21 00:30:49,646:INFO: 81/260 (epoch 3), train_loss = 46.143554687500, time/batch = 4.313569545746
2025-04-21 00:30:52,869:INFO: 82/260 (epoch 3), train_loss = -0.674836516380, time/batch = 3.223376035690
2025-04-21 00:31:01,105:INFO: 83/260 (epoch 3), train_loss = -1.035394906998, time/batch = 8.235792636871
2025-04-21 00:31:08,264:INFO: 84/260 (epoch 3), train_loss = -1.470308899879, time/batch = 7.159602403641
2025-04-21 00:31:13,423:INFO: 85/260 (epoch 3), train_loss = -2.244935750961, time/batch = 5.142478466034
2025-04-21 00:31:21,725:INFO: 86/260 (epoch 3), train_loss = 45.874416351318, time/batch = 8.302054166794
2025-04-21 00:31:25,319:INFO: 87/260 (epoch 3), train_loss = -0.359928667545, time/batch = 3.594597578049
2025-04-21 00:31:33,558:INFO: 88/260 (epoch 3), train_loss = -0.705275177956, time/batch = 8.223024129868
2025-04-21 00:31:34,605:INFO: 89/260 (epoch 3), train_loss = -1.017485260963, time/batch = 1.046941757202
2025-04-21 00:31:40,484:INFO: 90/260 (epoch 3), train_loss = -1.393493175507, time/batch = 5.879494428635
2025-04-21 00:31:43,877:INFO: 91/260 (epoch 3), train_loss = -2.029566287994, time/batch = 3.392678499222
2025-04-21 00:31:44,283:INFO: 92/260 (epoch 3), train_loss = -2.313152313232, time/batch = 0.406275510788
2025-04-21 00:31:48,222:INFO: 93/260 (epoch 3), train_loss = -2.142821788788, time/batch = 3.938581228256
2025-04-21 00:31:52,442:INFO: 94/260 (epoch 3), train_loss = 46.267234802246, time/batch = 4.220542669296
2025-04-21 00:31:55,585:INFO: 95/260 (epoch 3), train_loss = -0.618272483349, time/batch = 3.142671108246
2025-04-21 00:32:03,558:INFO: 96/260 (epoch 3), train_loss = -0.533956527710, time/batch = 7.972702741623
2025-04-21 00:32:11,015:INFO: 97/260 (epoch 3), train_loss = -0.570933103561, time/batch = 7.456978321075
2025-04-21 00:32:16,063:INFO: 98/260 (epoch 3), train_loss = -1.314553976059, time/batch = 5.048618793488
2025-04-21 00:32:24,630:INFO: 99/260 (epoch 3), train_loss = 45.974807739258, time/batch = 8.566503524780
2025-04-21 00:32:28,162:INFO: 100/260 (epoch 3), train_loss = -2.574339389801, time/batch = 3.532015800476
2025-04-21 00:32:36,337:INFO: 101/260 (epoch 3), train_loss = -1.999126434326, time/batch = 8.175143957138
2025-04-21 00:32:37,384:INFO: 102/260 (epoch 3), train_loss = -2.182305574417, time/batch = 1.046939373016
2025-04-21 00:32:43,652:INFO: 103/260 (epoch 3), train_loss = -2.553427934647, time/batch = 6.268249988556
2025-04-21 00:32:43,652:INFO: (epoch 3), loss = 5.917
2025-04-21 00:32:43,652:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:32:43,652:INFO: Saving model
2025-04-21 00:32:47,013:INFO: 104/260 (epoch 4), train_loss = -2.456703424454, time/batch = 3.345468044281
2025-04-21 00:32:47,404:INFO: 105/260 (epoch 4), train_loss = -2.394396543503, time/batch = 0.390648841858
2025-04-21 00:32:50,875:INFO: 106/260 (epoch 4), train_loss = -2.341747045517, time/batch = 3.471563100815
2025-04-21 00:32:55,268:INFO: 107/260 (epoch 4), train_loss = 46.121517181396, time/batch = 4.392548084259
2025-04-21 00:32:58,363:INFO: 108/260 (epoch 4), train_loss = -2.268154859543, time/batch = 3.095244884491
2025-04-21 00:33:06,350:INFO: 109/260 (epoch 4), train_loss = -2.499034643173, time/batch = 7.987021446228
2025-04-21 00:33:13,386:INFO: 110/260 (epoch 4), train_loss = -2.617594718933, time/batch = 7.035761117935
2025-04-21 00:33:18,451:INFO: 111/260 (epoch 4), train_loss = -2.453571319580, time/batch = 5.065133571625
2025-04-21 00:33:26,282:INFO: 112/260 (epoch 4), train_loss = 45.925106048584, time/batch = 7.830786466599
2025-04-21 00:33:29,861:INFO: 113/260 (epoch 4), train_loss = -1.584630012512, time/batch = 3.579315900803
2025-04-21 00:33:38,224:INFO: 114/260 (epoch 4), train_loss = -3.001915693283, time/batch = 8.362455844879
2025-04-21 00:33:39,271:INFO: 115/260 (epoch 4), train_loss = -3.130440235138, time/batch = 1.047577857971
2025-04-21 00:33:45,023:INFO: 116/260 (epoch 4), train_loss = -2.406855344772, time/batch = 5.751338481903
2025-04-21 00:33:48,384:INFO: 117/260 (epoch 4), train_loss = -2.153817176819, time/batch = 3.361185312271
2025-04-21 00:33:48,915:INFO: 118/260 (epoch 4), train_loss = -2.305770397186, time/batch = 0.531263113022
2025-04-21 00:33:52,463:INFO: 119/260 (epoch 4), train_loss = -2.565019130707, time/batch = 3.548036336899
2025-04-21 00:33:56,679:INFO: 120/260 (epoch 4), train_loss = 46.175079345703, time/batch = 4.215421676636
2025-04-21 00:33:59,790:INFO: 121/260 (epoch 4), train_loss = -3.073003292084, time/batch = 3.111669540405
2025-04-21 00:34:07,652:INFO: 122/260 (epoch 4), train_loss = -3.016410112381, time/batch = 7.861408472061
2025-04-21 00:34:15,014:INFO: 123/260 (epoch 4), train_loss = -3.046006917953, time/batch = 7.362313032150
2025-04-21 00:34:20,032:INFO: 124/260 (epoch 4), train_loss = -3.214321374893, time/batch = 5.017876863480
2025-04-21 00:34:28,159:INFO: 125/260 (epoch 4), train_loss = 45.908290863037, time/batch = 8.126724720001
2025-04-21 00:34:31,707:INFO: 126/260 (epoch 4), train_loss = -3.200267314911, time/batch = 3.532427549362
2025-04-21 00:34:40,242:INFO: 127/260 (epoch 4), train_loss = -2.780594348907, time/batch = 8.519916296005
2025-04-21 00:34:41,274:INFO: 128/260 (epoch 4), train_loss = -3.084217786789, time/batch = 1.032000303268
2025-04-21 00:34:47,041:INFO: 129/260 (epoch 4), train_loss = -3.388818740845, time/batch = 5.766933441162
2025-04-21 00:34:47,041:INFO: (epoch 4), loss = 4.813
2025-04-21 00:34:47,041:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:34:47,041:INFO: Saving model
2025-04-21 00:34:50,950:INFO: 130/260 (epoch 5), train_loss = -2.817018032074, time/batch = 3.893461465836
2025-04-21 00:34:51,356:INFO: 131/260 (epoch 5), train_loss = -3.183128595352, time/batch = 0.406275749207
2025-04-21 00:34:54,891:INFO: 132/260 (epoch 5), train_loss = -3.299062252045, time/batch = 3.534262418747
2025-04-21 00:34:59,063:INFO: 133/260 (epoch 5), train_loss = 46.116725921631, time/batch = 4.172601938248
2025-04-21 00:35:02,158:INFO: 134/260 (epoch 5), train_loss = -3.223749160767, time/batch = 3.094881534576
2025-04-21 00:35:10,207:INFO: 135/260 (epoch 5), train_loss = -3.591335773468, time/batch = 8.048537731171
2025-04-21 00:35:17,320:INFO: 136/260 (epoch 5), train_loss = -3.412932872772, time/batch = 7.113629579544
2025-04-21 00:35:22,963:INFO: 137/260 (epoch 5), train_loss = -3.001873016357, time/batch = 5.642807960510
2025-04-21 00:35:30,935:INFO: 138/260 (epoch 5), train_loss = 45.907314300537, time/batch = 7.971889972687
2025-04-21 00:35:34,498:INFO: 139/260 (epoch 5), train_loss = -3.274145603180, time/batch = 3.563302993774
2025-04-21 00:35:43,003:INFO: 140/260 (epoch 5), train_loss = -3.449890613556, time/batch = 8.504255056381
2025-04-21 00:35:44,519:INFO: 141/260 (epoch 5), train_loss = -4.042113780975, time/batch = 1.516196012497
2025-04-21 00:35:50,349:INFO: 142/260 (epoch 5), train_loss = -3.825760364532, time/batch = 5.829941987991
2025-04-21 00:35:53,803:INFO: 143/260 (epoch 5), train_loss = -3.522763013840, time/batch = 3.454121112823
2025-04-21 00:35:54,194:INFO: 144/260 (epoch 5), train_loss = -3.736410140991, time/batch = 0.390634775162
2025-04-21 00:35:57,743:INFO: 145/260 (epoch 5), train_loss = -3.914193630219, time/batch = 3.549768686295
2025-04-21 00:36:01,886:INFO: 146/260 (epoch 5), train_loss = 46.127429962158, time/batch = 4.126721620560
2025-04-21 00:36:04,965:INFO: 147/260 (epoch 5), train_loss = -1.942087531090, time/batch = 3.079180717468
2025-04-21 00:36:13,172:INFO: 148/260 (epoch 5), train_loss = -2.525606393814, time/batch = 8.206824302673
2025-04-21 00:36:20,331:INFO: 149/260 (epoch 5), train_loss = 0.534532427788, time/batch = 7.158950805664
2025-04-21 00:36:25,394:INFO: 150/260 (epoch 5), train_loss = 1.125000953674, time/batch = 5.063178062439
2025-04-21 00:36:33,444:INFO: 151/260 (epoch 5), train_loss = 45.914188385010, time/batch = 8.049875259399
2025-04-21 00:36:37,070:INFO: 152/260 (epoch 5), train_loss = -4.175655841827, time/batch = 3.626166582108
2025-04-21 00:36:45,604:INFO: 153/260 (epoch 5), train_loss = -0.414042115211, time/batch = 8.534660100937
2025-04-21 00:36:47,137:INFO: 154/260 (epoch 5), train_loss = 0.927226901054, time/batch = 1.532114505768
2025-04-21 00:36:53,453:INFO: 155/260 (epoch 5), train_loss = -3.656110048294, time/batch = 6.300365209579
2025-04-21 00:36:53,453:INFO: (epoch 5), loss = 4.832
2025-04-21 00:36:53,453:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:36:53,453:INFO: Saving model
2025-04-21 00:36:58,117:INFO: 156/260 (epoch 6), train_loss = -4.618228435516, time/batch = 4.633113861084
2025-04-21 00:36:58,524:INFO: 157/260 (epoch 6), train_loss = -4.465161323547, time/batch = 0.406839609146
2025-04-21 00:37:02,104:INFO: 158/260 (epoch 6), train_loss = -4.606327533722, time/batch = 3.579740285873
2025-04-21 00:37:06,323:INFO: 159/260 (epoch 6), train_loss = 46.089782714844, time/batch = 4.219698429108
2025-04-21 00:37:09,653:INFO: 160/260 (epoch 6), train_loss = -1.672638773918, time/batch = 3.329499244690
2025-04-21 00:37:17,533:INFO: 161/260 (epoch 6), train_loss = -2.245058774948, time/batch = 7.880093574524
2025-04-21 00:37:24,722:INFO: 162/260 (epoch 6), train_loss = -2.673690080643, time/batch = 7.189389467239
2025-04-21 00:37:29,883:INFO: 163/260 (epoch 6), train_loss = -3.065517902374, time/batch = 5.160871267319
2025-04-21 00:37:38,190:INFO: 164/260 (epoch 6), train_loss = 45.942394256592, time/batch = 8.306896448135
2025-04-21 00:37:41,930:INFO: 165/260 (epoch 6), train_loss = -2.283055543900, time/batch = 3.740524291992
2025-04-21 00:37:51,046:INFO: 166/260 (epoch 6), train_loss = -2.531488895416, time/batch = 9.115511655807
2025-04-21 00:37:52,093:INFO: 167/260 (epoch 6), train_loss = -4.592750549316, time/batch = 1.046952962875
2025-04-21 00:37:58,474:INFO: 168/260 (epoch 6), train_loss = 2.103600740433, time/batch = 6.381480216980
2025-04-21 00:38:01,882:INFO: 169/260 (epoch 6), train_loss = 9.856868743896, time/batch = 3.407943487167
2025-04-21 00:38:02,304:INFO: 170/260 (epoch 6), train_loss = 7.010733604431, time/batch = 0.421902418137
2025-04-21 00:38:05,961:INFO: 171/260 (epoch 6), train_loss = 0.307680189610, time/batch = 3.656935930252
2025-04-21 00:38:10,260:INFO: 172/260 (epoch 6), train_loss = 46.089221954346, time/batch = 4.298582553864
2025-04-21 00:38:13,417:INFO: 173/260 (epoch 6), train_loss = -0.340219914913, time/batch = 3.156940937042
2025-04-21 00:38:21,467:INFO: 174/260 (epoch 6), train_loss = 2.680781126022, time/batch = 8.050235986710
2025-04-21 00:38:28,548:INFO: 175/260 (epoch 6), train_loss = 4.130735874176, time/batch = 7.081006765366
2025-04-21 00:38:33,597:INFO: 176/260 (epoch 6), train_loss = -1.685239911079, time/batch = 5.032957792282
2025-04-21 00:38:41,725:INFO: 177/260 (epoch 6), train_loss = 45.900562286377, time/batch = 8.128081560135
2025-04-21 00:38:45,413:INFO: 178/260 (epoch 6), train_loss = -0.668174743652, time/batch = 3.688182353973
2025-04-21 00:38:53,653:INFO: 179/260 (epoch 6), train_loss = -1.092858672142, time/batch = 8.240427017212
2025-04-21 00:38:54,951:INFO: 180/260 (epoch 6), train_loss = -1.759496569633, time/batch = 1.298123359680
2025-04-21 00:39:01,048:INFO: 181/260 (epoch 6), train_loss = -2.017730951309, time/batch = 6.096318721771
2025-04-21 00:39:01,048:INFO: (epoch 6), loss = 6.531
2025-04-21 00:39:01,048:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:39:01,048:INFO: Saving model
2025-04-21 00:39:04,816:INFO: 182/260 (epoch 7), train_loss = -1.775635361671, time/batch = 3.737514734268
2025-04-21 00:39:05,270:INFO: 183/260 (epoch 7), train_loss = -2.310839176178, time/batch = 0.453577041626
2025-04-21 00:39:09,538:INFO: 184/260 (epoch 7), train_loss = -2.579333305359, time/batch = 4.267488718033
2025-04-21 00:39:14,152:INFO: 185/260 (epoch 7), train_loss = 46.158786773682, time/batch = 4.614118814468
2025-04-21 00:39:17,434:INFO: 186/260 (epoch 7), train_loss = -2.751084327698, time/batch = 3.282516241074
2025-04-21 00:39:25,767:INFO: 187/260 (epoch 7), train_loss = -3.574249744415, time/batch = 8.333177566528
2025-04-21 00:39:32,989:INFO: 188/260 (epoch 7), train_loss = -2.645982027054, time/batch = 7.221798181534
2025-04-21 00:39:38,164:INFO: 189/260 (epoch 7), train_loss = -2.323524236679, time/batch = 5.174731016159
2025-04-21 00:39:46,511:INFO: 190/260 (epoch 7), train_loss = 45.928070068359, time/batch = 8.346788644791
2025-04-21 00:39:50,278:INFO: 191/260 (epoch 7), train_loss = -1.555760145187, time/batch = 3.767348527908
2025-04-21 00:39:58,632:INFO: 192/260 (epoch 7), train_loss = -3.259284496307, time/batch = 8.353879213333
2025-04-21 00:39:59,695:INFO: 193/260 (epoch 7), train_loss = -2.524981498718, time/batch = 1.063518047333
2025-04-21 00:40:06,076:INFO: 194/260 (epoch 7), train_loss = -3.210267543793, time/batch = 6.380137443542
2025-04-21 00:40:09,513:INFO: 195/260 (epoch 7), train_loss = -3.125109195709, time/batch = 3.436964035034
2025-04-21 00:40:09,920:INFO: 196/260 (epoch 7), train_loss = -3.762865304947, time/batch = 0.407885551453
2025-04-21 00:40:13,842:INFO: 197/260 (epoch 7), train_loss = -3.814024448395, time/batch = 3.921759843826
2025-04-21 00:40:18,184:INFO: 198/260 (epoch 7), train_loss = 46.153720855713, time/batch = 4.341461896896
2025-04-21 00:40:21,617:INFO: 199/260 (epoch 7), train_loss = -2.953786373138, time/batch = 3.433258056641
2025-04-21 00:40:29,947:INFO: 200/260 (epoch 7), train_loss = -2.640587329865, time/batch = 8.329658746719
2025-04-21 00:40:37,077:INFO: 201/260 (epoch 7), train_loss = -2.002557992935, time/batch = 7.130954027176
2025-04-21 00:40:42,191:INFO: 202/260 (epoch 7), train_loss = -3.114125967026, time/batch = 5.113130807877
2025-04-21 00:40:50,368:INFO: 203/260 (epoch 7), train_loss = 45.904567718506, time/batch = 8.176890373230
2025-04-21 00:40:54,252:INFO: 204/260 (epoch 7), train_loss = -3.751663208008, time/batch = 3.884943962097
2025-04-21 00:41:03,130:INFO: 205/260 (epoch 7), train_loss = -0.786592721939, time/batch = 8.877541065216
2025-04-21 00:41:04,193:INFO: 206/260 (epoch 7), train_loss = -2.202564239502, time/batch = 1.062568664551
2025-04-21 00:41:10,116:INFO: 207/260 (epoch 7), train_loss = -2.836961984634, time/batch = 5.923238515854
2025-04-21 00:41:10,116:INFO: (epoch 7), loss = 4.794
2025-04-21 00:41:10,116:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:41:10,116:INFO: Saving model
2025-04-21 00:41:13,514:INFO: 208/260 (epoch 8), train_loss = -2.099242210388, time/batch = 3.366905689240
2025-04-21 00:41:13,921:INFO: 209/260 (epoch 8), train_loss = -2.864448308945, time/batch = 0.406720876694
2025-04-21 00:41:17,674:INFO: 210/260 (epoch 8), train_loss = -3.655720472336, time/batch = 3.753676891327
2025-04-21 00:41:22,036:INFO: 211/260 (epoch 8), train_loss = 46.200370788574, time/batch = 4.361493349075
2025-04-21 00:41:25,257:INFO: 212/260 (epoch 8), train_loss = 13.790100097656, time/batch = 3.221147298813
2025-04-21 00:41:33,401:INFO: 213/260 (epoch 8), train_loss = 18.059869766235, time/batch = 8.144050598145
2025-04-21 00:41:41,844:INFO: 214/260 (epoch 8), train_loss = 11.005763053894, time/batch = 8.442839860916
2025-04-21 00:41:47,137:INFO: 215/260 (epoch 8), train_loss = 5.333866119385, time/batch = 5.292632818222
2025-04-21 00:41:56,679:INFO: 216/260 (epoch 8), train_loss = 45.968708038330, time/batch = 9.542559623718
2025-04-21 00:42:00,582:INFO: 217/260 (epoch 8), train_loss = -3.225661993027, time/batch = 3.902544260025
2025-04-21 00:42:09,291:INFO: 218/260 (epoch 8), train_loss = -2.933712005615, time/batch = 8.709281206131
2025-04-21 00:42:10,352:INFO: 219/260 (epoch 8), train_loss = -3.067701339722, time/batch = 1.061061382294
2025-04-21 00:42:16,528:INFO: 220/260 (epoch 8), train_loss = -3.335581064224, time/batch = 6.175945758820
2025-04-21 00:42:20,657:INFO: 221/260 (epoch 8), train_loss = -3.391154050827, time/batch = 4.127605676651
2025-04-21 00:42:21,059:INFO: 222/260 (epoch 8), train_loss = -2.707219362259, time/batch = 0.401436090469
2025-04-21 00:42:25,160:INFO: 223/260 (epoch 8), train_loss = -3.042151927948, time/batch = 4.100251197815
2025-04-21 00:42:29,419:INFO: 224/260 (epoch 8), train_loss = 46.084194183350, time/batch = 4.258982896805
2025-04-21 00:42:32,679:INFO: 225/260 (epoch 8), train_loss = -3.471994400024, time/batch = 3.260085582733
2025-04-21 00:42:41,649:INFO: 226/260 (epoch 8), train_loss = -3.352835893631, time/batch = 8.970432281494
2025-04-21 00:42:49,795:INFO: 227/260 (epoch 8), train_loss = -3.150466442108, time/batch = 8.145421266556
2025-04-21 00:42:56,179:INFO: 228/260 (epoch 8), train_loss = -3.643775939941, time/batch = 6.383446216583
2025-04-21 00:43:04,360:INFO: 229/260 (epoch 8), train_loss = 45.876533508301, time/batch = 8.181142807007
2025-04-21 00:43:08,550:INFO: 230/260 (epoch 8), train_loss = -3.217962980270, time/batch = 4.190316438675
2025-04-21 00:43:16,768:INFO: 231/260 (epoch 8), train_loss = -3.538338661194, time/batch = 8.217712879181
2025-04-21 00:43:17,808:INFO: 232/260 (epoch 8), train_loss = -3.476839303970, time/batch = 1.039912939072
2025-04-21 00:43:23,906:INFO: 233/260 (epoch 8), train_loss = -3.274539947510, time/batch = 6.096803188324
2025-04-21 00:43:23,906:INFO: (epoch 8), loss = 6.726
2025-04-21 00:43:23,907:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:43:23,907:INFO: Saving model
2025-04-21 00:43:27,302:INFO: 234/260 (epoch 9), train_loss = -3.129655122757, time/batch = 3.366315841675
2025-04-21 00:43:27,713:INFO: 235/260 (epoch 9), train_loss = -3.269529104233, time/batch = 0.410795450211
2025-04-21 00:43:31,331:INFO: 236/260 (epoch 9), train_loss = -3.440975666046, time/batch = 3.616924047470
2025-04-21 00:43:35,757:INFO: 237/260 (epoch 9), train_loss = 46.076335906982, time/batch = 4.426174402237
2025-04-21 00:43:38,913:INFO: 238/260 (epoch 9), train_loss = -3.150815963745, time/batch = 3.154992818832
2025-04-21 00:43:47,060:INFO: 239/260 (epoch 9), train_loss = -3.516641616821, time/batch = 8.147616147995
2025-04-21 00:43:56,981:INFO: 240/260 (epoch 9), train_loss = -2.098648786545, time/batch = 9.920312166214
2025-04-21 00:44:02,231:INFO: 241/260 (epoch 9), train_loss = -2.232882738113, time/batch = 5.250058412552
2025-04-21 00:44:10,698:INFO: 242/260 (epoch 9), train_loss = 45.934276580811, time/batch = 8.467284679413
2025-04-21 00:44:14,335:INFO: 243/260 (epoch 9), train_loss = -3.814045667648, time/batch = 3.635875225067
2025-04-21 00:44:22,804:INFO: 244/260 (epoch 9), train_loss = -2.713186502457, time/batch = 8.469404697418
2025-04-21 00:44:23,874:INFO: 245/260 (epoch 9), train_loss = -2.170821905136, time/batch = 1.068528413773
2025-04-21 00:44:29,809:INFO: 246/260 (epoch 9), train_loss = -4.195593357086, time/batch = 5.934616804123
2025-04-21 00:44:33,253:INFO: 247/260 (epoch 9), train_loss = -4.203020095825, time/batch = 3.443875312805
2025-04-21 00:44:33,659:INFO: 248/260 (epoch 9), train_loss = -4.111993789673, time/batch = 0.404458999634
2025-04-21 00:44:37,429:INFO: 249/260 (epoch 9), train_loss = -4.352366924286, time/batch = 3.770237922668
2025-04-21 00:44:41,903:INFO: 250/260 (epoch 9), train_loss = 46.059368133545, time/batch = 4.473965167999
2025-04-21 00:44:44,962:INFO: 251/260 (epoch 9), train_loss = -1.301050901413, time/batch = 3.057975292206
2025-04-21 00:44:53,197:INFO: 252/260 (epoch 9), train_loss = -1.926625251770, time/batch = 8.234657287598
2025-04-21 00:45:00,684:INFO: 253/260 (epoch 9), train_loss = -1.511077761650, time/batch = 7.485764265060
2025-04-21 00:45:05,951:INFO: 254/260 (epoch 9), train_loss = -1.764280676842, time/batch = 5.266777515411
2025-04-21 00:45:14,411:INFO: 255/260 (epoch 9), train_loss = 45.978466033936, time/batch = 8.459091186523
2025-04-21 00:45:18,162:INFO: 256/260 (epoch 9), train_loss = -4.435790061951, time/batch = 3.751202344894
2025-04-21 00:45:26,464:INFO: 257/260 (epoch 9), train_loss = -1.413413286209, time/batch = 8.302192687988
2025-04-21 00:45:27,511:INFO: 258/260 (epoch 9), train_loss = -2.327133655548, time/batch = 1.046954154968
2025-04-21 00:45:33,764:INFO: 259/260 (epoch 9), train_loss = -3.240651845932, time/batch = 6.252402305603
2025-04-21 00:45:33,764:INFO: (epoch 9), loss = 4.605
2025-04-21 00:45:33,764:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 00:45:33,764:INFO: Saving model
2025-04-21 00:45:33,779:INFO: Best epoch 0, Best loss 2.4532792636981378
2025-04-21 16:30:26,006:INFO: Training begin
2025-04-21 16:30:32,287:INFO: 0/260 (epoch 0), train_loss = 3.590157508850, time/batch = 6.281584501266
2025-04-21 16:30:35,710:INFO: 1/260 (epoch 0), train_loss = 3.566318988800, time/batch = 3.422555446625
2025-04-21 16:30:36,319:INFO: 2/260 (epoch 0), train_loss = 3.483072757721, time/batch = 0.609415769577
2025-04-21 16:30:40,649:INFO: 3/260 (epoch 0), train_loss = 3.409304618835, time/batch = 4.329758882523
2025-04-21 16:30:49,028:INFO: 4/260 (epoch 0), train_loss = 3.593544006348, time/batch = 8.378863334656
2025-04-21 16:30:50,090:INFO: 5/260 (epoch 0), train_loss = 3.281444787979, time/batch = 1.062571763992
2025-04-21 16:30:53,842:INFO: 6/260 (epoch 0), train_loss = 3.258989810944, time/batch = 3.751049518585
2025-04-21 16:30:59,828:INFO: 7/260 (epoch 0), train_loss = 3.212875604630, time/batch = 5.986088752747
2025-04-21 16:31:08,332:INFO: 8/260 (epoch 0), train_loss = 3.150344610214, time/batch = 8.504415273666
2025-04-21 16:31:15,835:INFO: 9/260 (epoch 0), train_loss = 3.089298725128, time/batch = 7.502944469452
2025-04-21 16:31:19,102:INFO: 10/260 (epoch 0), train_loss = 3.004936456680, time/batch = 3.266892194748
2025-04-21 16:31:24,134:INFO: 11/260 (epoch 0), train_loss = 2.914126873016, time/batch = 5.032466888428
2025-04-21 16:31:32,672:INFO: 12/260 (epoch 0), train_loss = 2.798452854156, time/batch = 8.537897825241
2025-04-21 16:31:37,064:INFO: 13/260 (epoch 0), train_loss = 3.290415525436, time/batch = 4.391834735870
2025-04-21 16:31:40,505:INFO: 14/260 (epoch 0), train_loss = 2.507043838501, time/batch = 3.440801382065
2025-04-21 16:31:40,927:INFO: 15/260 (epoch 0), train_loss = 2.316776275635, time/batch = 0.406275272369
2025-04-21 16:31:44,662:INFO: 16/260 (epoch 0), train_loss = 2.057472229004, time/batch = 3.735544204712
2025-04-21 16:31:52,899:INFO: 17/260 (epoch 0), train_loss = 3.057825088501, time/batch = 8.236797571182
2025-04-21 16:31:53,930:INFO: 18/260 (epoch 0), train_loss = 1.836649894714, time/batch = 1.031319618225
2025-04-21 16:31:57,541:INFO: 19/260 (epoch 0), train_loss = 1.914323687553, time/batch = 3.610576152802
2025-04-21 16:32:03,558:INFO: 20/260 (epoch 0), train_loss = 1.829492807388, time/batch = 6.017455339432
2025-04-21 16:32:11,999:INFO: 21/260 (epoch 0), train_loss = 1.583360671997, time/batch = 8.440992593765
2025-04-21 16:32:19,539:INFO: 22/260 (epoch 0), train_loss = 1.456268548965, time/batch = 7.539142131805
2025-04-21 16:32:22,948:INFO: 23/260 (epoch 0), train_loss = 1.313130378723, time/batch = 3.409818887711
2025-04-21 16:32:28,357:INFO: 24/260 (epoch 0), train_loss = 1.189311146736, time/batch = 5.408111572266
2025-04-21 16:32:37,174:INFO: 25/260 (epoch 0), train_loss = 1.088925242424, time/batch = 8.817501783371
2025-04-21 16:32:37,174:INFO: (epoch 0), loss = 2.607
2025-04-21 16:32:37,182:INFO: Best epoch 0, Best loss 2.6074562668800354
2025-04-21 16:32:37,182:INFO: Saving model
2025-04-21 16:32:42,223:INFO: 26/260 (epoch 1), train_loss = 8.256573677063, time/batch = 4.937703132629
2025-04-21 16:32:45,708:INFO: 27/260 (epoch 1), train_loss = 1.246921181679, time/batch = 3.469814062119
2025-04-21 16:32:46,115:INFO: 28/260 (epoch 1), train_loss = 1.146846175194, time/batch = 0.406695127487
2025-04-21 16:32:49,804:INFO: 29/260 (epoch 1), train_loss = 0.988710105419, time/batch = 3.688843965530
2025-04-21 16:32:57,871:INFO: 30/260 (epoch 1), train_loss = 5.824910163879, time/batch = 8.067674636841
2025-04-21 16:32:58,920:INFO: 31/260 (epoch 1), train_loss = 0.647541224957, time/batch = 1.048557758331
2025-04-21 16:33:02,578:INFO: 32/260 (epoch 1), train_loss = 0.702062845230, time/batch = 3.658482551575
2025-04-21 16:33:08,658:INFO: 33/260 (epoch 1), train_loss = 0.587272047997, time/batch = 6.079880237579
2025-04-21 16:33:17,099:INFO: 34/260 (epoch 1), train_loss = 0.560372412205, time/batch = 8.441025733948
2025-04-21 16:33:24,494:INFO: 35/260 (epoch 1), train_loss = 0.508966445923, time/batch = 7.395099878311
2025-04-21 16:33:27,792:INFO: 36/260 (epoch 1), train_loss = 0.396905958652, time/batch = 3.298035383224
2025-04-21 16:33:32,890:INFO: 37/260 (epoch 1), train_loss = 0.280618101358, time/batch = 5.097051620483
2025-04-21 16:33:41,958:INFO: 38/260 (epoch 1), train_loss = 0.131502866745, time/batch = 9.068591594696
2025-04-21 16:33:46,747:INFO: 39/260 (epoch 1), train_loss = 18.302528381348, time/batch = 4.788466215134
2025-04-21 16:33:50,608:INFO: 40/260 (epoch 1), train_loss = 0.475268393755, time/batch = 3.861154079437
2025-04-21 16:33:51,092:INFO: 41/260 (epoch 1), train_loss = 0.448697417974, time/batch = 0.484407901764
2025-04-21 16:33:54,890:INFO: 42/260 (epoch 1), train_loss = 0.403719395399, time/batch = 3.797656536102
2025-04-21 16:34:03,346:INFO: 43/260 (epoch 1), train_loss = 15.697254180908, time/batch = 8.455931663513
2025-04-21 16:34:04,503:INFO: 44/260 (epoch 1), train_loss = -0.234454974532, time/batch = 1.156822204590
2025-04-21 16:34:08,332:INFO: 45/260 (epoch 1), train_loss = 0.190937772393, time/batch = 3.829258680344
2025-04-21 16:34:14,741:INFO: 46/260 (epoch 1), train_loss = -0.016549512744, time/batch = 6.408749818802
2025-04-21 16:34:23,697:INFO: 47/260 (epoch 1), train_loss = -0.288457214832, time/batch = 8.956013202667
2025-04-21 16:34:31,388:INFO: 48/260 (epoch 1), train_loss = -0.322288960218, time/batch = 7.691284656525
2025-04-21 16:34:34,795:INFO: 49/260 (epoch 1), train_loss = -0.439092159271, time/batch = 3.407009601593
2025-04-21 16:34:40,204:INFO: 50/260 (epoch 1), train_loss = -0.557502686977, time/batch = 5.409474849701
2025-04-21 16:34:49,145:INFO: 51/260 (epoch 1), train_loss = -0.697930634022, time/batch = 8.940413475037
2025-04-21 16:34:49,145:INFO: (epoch 1), loss = 2.086
2025-04-21 16:34:49,145:INFO: Best epoch 1, Best loss 2.0862051002108135
2025-04-21 16:34:49,145:INFO: Saving model
2025-04-21 16:34:53,708:INFO: 52/260 (epoch 2), train_loss = 30.115621566772, time/batch = 4.516348123550
2025-04-21 16:34:57,349:INFO: 53/260 (epoch 2), train_loss = 0.788746714592, time/batch = 3.641314029694
2025-04-21 16:34:57,819:INFO: 54/260 (epoch 2), train_loss = 0.880877315998, time/batch = 0.469291687012
2025-04-21 16:35:01,804:INFO: 55/260 (epoch 2), train_loss = 0.875296533108, time/batch = 3.985522985458
2025-04-21 16:35:10,308:INFO: 56/260 (epoch 2), train_loss = 32.225486755371, time/batch = 8.503496885300
2025-04-21 16:35:11,417:INFO: 57/260 (epoch 2), train_loss = -0.964946210384, time/batch = 1.109449863434
2025-04-21 16:35:15,351:INFO: 58/260 (epoch 2), train_loss = 0.427385061979, time/batch = 3.933450937271
2025-04-21 16:35:21,994:INFO: 59/260 (epoch 2), train_loss = -0.018452854827, time/batch = 6.643935441971
2025-04-21 16:35:30,903:INFO: 60/260 (epoch 2), train_loss = -0.879801988602, time/batch = 8.908312320709
2025-04-21 16:35:38,874:INFO: 61/260 (epoch 2), train_loss = -0.909485757351, time/batch = 7.971202373505
2025-04-21 16:35:42,204:INFO: 62/260 (epoch 2), train_loss = -0.958647549152, time/batch = 3.329686164856
2025-04-21 16:35:47,752:INFO: 63/260 (epoch 2), train_loss = -1.024007201195, time/batch = 5.548631429672
2025-04-21 16:35:56,270:INFO: 64/260 (epoch 2), train_loss = -1.127146720886, time/batch = 8.517598152161
2025-04-21 16:36:00,788:INFO: 65/260 (epoch 2), train_loss = 23.210451126099, time/batch = 4.517946004868
2025-04-21 16:36:04,618:INFO: 66/260 (epoch 2), train_loss = 0.807436764240, time/batch = 3.829863309860
2025-04-21 16:36:05,024:INFO: 67/260 (epoch 2), train_loss = 0.887581050396, time/batch = 0.406293869019
2025-04-21 16:36:08,759:INFO: 68/260 (epoch 2), train_loss = 0.768865406513, time/batch = 3.735366582870
2025-04-21 16:36:17,607:INFO: 69/260 (epoch 2), train_loss = 38.576309204102, time/batch = 8.847604751587
2025-04-21 16:36:18,779:INFO: 70/260 (epoch 2), train_loss = -1.159057974815, time/batch = 1.171953678131
2025-04-21 16:36:23,406:INFO: 71/260 (epoch 2), train_loss = 0.302878677845, time/batch = 4.627333641052
2025-04-21 16:36:30,565:INFO: 72/260 (epoch 2), train_loss = -0.145238578320, time/batch = 7.158280134201
2025-04-21 16:36:39,819:INFO: 73/260 (epoch 2), train_loss = -1.083508729935, time/batch = 9.254562139511
2025-04-21 16:36:47,230:INFO: 74/260 (epoch 2), train_loss = -1.073133707047, time/batch = 7.410568714142
2025-04-21 16:36:50,497:INFO: 75/260 (epoch 2), train_loss = -1.141445994377, time/batch = 3.267601013184
2025-04-21 16:36:55,937:INFO: 76/260 (epoch 2), train_loss = -1.234488487244, time/batch = 5.439461469650
2025-04-21 16:37:04,628:INFO: 77/260 (epoch 2), train_loss = -1.376081347466, time/batch = 8.691407680511
2025-04-21 16:37:04,644:INFO: (epoch 2), loss = 4.491
2025-04-21 16:37:04,644:INFO: Best epoch 1, Best loss 2.0862051002108135
2025-04-21 16:37:04,644:INFO: Saving model
2025-04-21 16:37:09,224:INFO: 78/260 (epoch 3), train_loss = 18.237323760986, time/batch = 4.548863649368
2025-04-21 16:37:13,008:INFO: 79/260 (epoch 3), train_loss = 1.019839286804, time/batch = 3.784394502640
2025-04-21 16:37:13,478:INFO: 80/260 (epoch 3), train_loss = 1.239852070808, time/batch = 0.469875335693
2025-04-21 16:37:17,355:INFO: 81/260 (epoch 3), train_loss = 1.175521612167, time/batch = 3.876481294632
2025-04-21 16:37:26,123:INFO: 82/260 (epoch 3), train_loss = 42.101188659668, time/batch = 8.768429756165
2025-04-21 16:37:27,264:INFO: 83/260 (epoch 3), train_loss = -1.485441923141, time/batch = 1.140852928162
2025-04-21 16:37:30,986:INFO: 84/260 (epoch 3), train_loss = 0.588877201080, time/batch = 3.721994638443
2025-04-21 16:37:37,582:INFO: 85/260 (epoch 3), train_loss = -0.004834026098, time/batch = 6.596118450165
2025-04-21 16:37:46,429:INFO: 86/260 (epoch 3), train_loss = -1.377466678619, time/batch = 8.847468376160
2025-04-21 16:37:54,167:INFO: 87/260 (epoch 3), train_loss = -1.354068756104, time/batch = 7.737373113632
2025-04-21 16:37:57,386:INFO: 88/260 (epoch 3), train_loss = -1.409768700600, time/batch = 3.219451665878
2025-04-21 16:38:02,717:INFO: 89/260 (epoch 3), train_loss = -1.488520979881, time/batch = 5.330365657806
2025-04-21 16:38:11,087:INFO: 90/260 (epoch 3), train_loss = -1.589174985886, time/batch = 8.370387077332
2025-04-21 16:38:16,028:INFO: 91/260 (epoch 3), train_loss = 12.824092864990, time/batch = 4.940696477890
2025-04-21 16:38:19,654:INFO: 92/260 (epoch 3), train_loss = 1.518393158913, time/batch = 3.626122951508
2025-04-21 16:38:20,107:INFO: 93/260 (epoch 3), train_loss = 1.709171772003, time/batch = 0.453156948090
2025-04-21 16:38:24,093:INFO: 94/260 (epoch 3), train_loss = 1.574666380882, time/batch = 3.985700607300
2025-04-21 16:38:32,757:INFO: 95/260 (epoch 3), train_loss = 34.502170562744, time/batch = 8.664366722107
2025-04-21 16:38:33,788:INFO: 96/260 (epoch 3), train_loss = -1.644217491150, time/batch = 1.031318664551
2025-04-21 16:38:37,417:INFO: 97/260 (epoch 3), train_loss = 0.821640253067, time/batch = 3.628201246262
2025-04-21 16:38:43,654:INFO: 98/260 (epoch 3), train_loss = 0.053521130234, time/batch = 6.237630844116
2025-04-21 16:38:52,359:INFO: 99/260 (epoch 3), train_loss = -1.495971798897, time/batch = 8.704681396484
2025-04-21 16:38:59,909:INFO: 100/260 (epoch 3), train_loss = -1.437821149826, time/batch = 7.550051212311
2025-04-21 16:39:03,129:INFO: 101/260 (epoch 3), train_loss = -1.494184136391, time/batch = 3.219901561737
2025-04-21 16:39:08,723:INFO: 102/260 (epoch 3), train_loss = -1.592105865479, time/batch = 5.594133853912
2025-04-21 16:39:17,354:INFO: 103/260 (epoch 3), train_loss = -1.732047080994, time/batch = 8.631406307220
2025-04-21 16:39:17,354:INFO: (epoch 3), loss = 3.818
2025-04-21 16:39:17,354:INFO: Best epoch 1, Best loss 2.0862051002108135
2025-04-21 16:39:17,354:INFO: Saving model
2025-04-21 16:39:21,840:INFO: 104/260 (epoch 4), train_loss = 9.537778854370, time/batch = 4.439089536667
2025-04-21 16:39:25,280:INFO: 105/260 (epoch 4), train_loss = 1.594309806824, time/batch = 3.439137697220
2025-04-21 16:39:25,670:INFO: 106/260 (epoch 4), train_loss = 1.784728884697, time/batch = 0.390664339066
2025-04-21 16:39:29,389:INFO: 107/260 (epoch 4), train_loss = 1.744152069092, time/batch = 3.703662157059
2025-04-21 16:39:37,709:INFO: 108/260 (epoch 4), train_loss = 16.869972229004, time/batch = 8.319074869156
2025-04-21 16:39:38,771:INFO: 109/260 (epoch 4), train_loss = -1.606591224670, time/batch = 1.062571525574
2025-04-21 16:39:42,397:INFO: 110/260 (epoch 4), train_loss = 0.776875376701, time/batch = 3.626132249832
2025-04-21 16:39:48,573:INFO: 111/260 (epoch 4), train_loss = 0.004051080905, time/batch = 6.175883531570
2025-04-21 16:39:57,687:INFO: 112/260 (epoch 4), train_loss = -1.362708926201, time/batch = 9.113921403885
2025-04-21 16:40:04,957:INFO: 113/260 (epoch 4), train_loss = -1.357558131218, time/batch = 7.269680023193
2025-04-21 16:40:08,349:INFO: 114/260 (epoch 4), train_loss = -1.289718627930, time/batch = 3.392052173615
2025-04-21 16:40:13,773:INFO: 115/260 (epoch 4), train_loss = -1.288417816162, time/batch = 5.424187660217
2025-04-21 16:40:21,853:INFO: 116/260 (epoch 4), train_loss = -1.415570378304, time/batch = 8.079971313477
2025-04-21 16:40:26,496:INFO: 117/260 (epoch 4), train_loss = 6.583870410919, time/batch = 4.642653942108
2025-04-21 16:40:29,951:INFO: 118/260 (epoch 4), train_loss = 0.085567146540, time/batch = 3.455597639084
2025-04-21 16:40:30,357:INFO: 119/260 (epoch 4), train_loss = 0.147834748030, time/batch = 0.406277656555
2025-04-21 16:40:34,015:INFO: 120/260 (epoch 4), train_loss = 0.085170701146, time/batch = 3.657612800598
2025-04-21 16:40:42,550:INFO: 121/260 (epoch 4), train_loss = 8.509883880615, time/batch = 8.535166740417
2025-04-21 16:40:43,645:INFO: 122/260 (epoch 4), train_loss = -1.410398483276, time/batch = 1.094788074493
2025-04-21 16:40:47,271:INFO: 123/260 (epoch 4), train_loss = -0.200634405017, time/batch = 3.625672578812
2025-04-21 16:40:53,523:INFO: 124/260 (epoch 4), train_loss = -0.565406799316, time/batch = 6.251773118973
2025-04-21 16:41:01,729:INFO: 125/260 (epoch 4), train_loss = -1.254327297211, time/batch = 8.206582307816
2025-04-21 16:41:08,919:INFO: 126/260 (epoch 4), train_loss = -1.224567413330, time/batch = 7.189772605896
2025-04-21 16:41:12,154:INFO: 127/260 (epoch 4), train_loss = -1.258969783783, time/batch = 3.235063791275
2025-04-21 16:41:17,193:INFO: 128/260 (epoch 4), train_loss = -1.319092273712, time/batch = 5.039393901825
2025-04-21 16:41:25,291:INFO: 129/260 (epoch 4), train_loss = -1.426284193993, time/batch = 8.097704887390
2025-04-21 16:41:25,291:INFO: (epoch 4), loss = 1.182
2025-04-21 16:41:25,291:INFO: Best epoch 4, Best loss 1.1824595936430762
2025-04-21 16:41:25,291:INFO: Saving model
2025-04-21 16:41:29,714:INFO: 130/260 (epoch 5), train_loss = 4.513364315033, time/batch = 4.376184940338
2025-04-21 16:41:33,184:INFO: 131/260 (epoch 5), train_loss = 0.370640695095, time/batch = 3.469411849976
2025-04-21 16:41:33,590:INFO: 132/260 (epoch 5), train_loss = 0.518723487854, time/batch = 0.406278371811
2025-04-21 16:41:37,216:INFO: 133/260 (epoch 5), train_loss = 0.625933766365, time/batch = 3.626154661179
2025-04-21 16:41:45,530:INFO: 134/260 (epoch 5), train_loss = 3.779047012329, time/batch = 8.314124822617
2025-04-21 16:41:46,562:INFO: 135/260 (epoch 5), train_loss = -1.557956218719, time/batch = 1.031776666641
2025-04-21 16:41:50,142:INFO: 136/260 (epoch 5), train_loss = 0.359820067883, time/batch = 3.580433607101
2025-04-21 16:41:56,612:INFO: 137/260 (epoch 5), train_loss = -0.124582402408, time/batch = 6.470171689987
2025-04-21 16:42:04,915:INFO: 138/260 (epoch 5), train_loss = -1.353215575218, time/batch = 8.302981138229
2025-04-21 16:42:12,747:INFO: 139/260 (epoch 5), train_loss = -1.463267803192, time/batch = 7.831460237503
2025-04-21 16:42:15,889:INFO: 140/260 (epoch 5), train_loss = -1.485717654228, time/batch = 3.142493724823
2025-04-21 16:42:21,126:INFO: 141/260 (epoch 5), train_loss = -1.529602289200, time/batch = 5.236376523972
2025-04-21 16:42:29,269:INFO: 142/260 (epoch 5), train_loss = -1.626277923584, time/batch = 8.143430471420
2025-04-21 16:42:33,895:INFO: 143/260 (epoch 5), train_loss = 3.505286455154, time/batch = 4.625745534897
2025-04-21 16:42:37,319:INFO: 144/260 (epoch 5), train_loss = 0.636522769928, time/batch = 3.423599958420
2025-04-21 16:42:37,727:INFO: 145/260 (epoch 5), train_loss = 0.718500971794, time/batch = 0.408264398575
2025-04-21 16:42:41,321:INFO: 146/260 (epoch 5), train_loss = 0.634842038155, time/batch = 3.594665288925
2025-04-21 16:42:49,578:INFO: 147/260 (epoch 5), train_loss = 3.060691356659, time/batch = 8.256528615952
2025-04-21 16:42:50,594:INFO: 148/260 (epoch 5), train_loss = -1.825587749481, time/batch = 1.015690088272
2025-04-21 16:42:54,313:INFO: 149/260 (epoch 5), train_loss = 0.320948332548, time/batch = 3.719467163086
2025-04-21 16:43:00,643:INFO: 150/260 (epoch 5), train_loss = -0.226787775755, time/batch = 6.330069303513
2025-04-21 16:43:09,923:INFO: 151/260 (epoch 5), train_loss = -1.761481165886, time/batch = 9.279739856720
2025-04-21 16:43:17,463:INFO: 152/260 (epoch 5), train_loss = -1.737666010857, time/batch = 7.539684057236
2025-04-21 16:43:21,058:INFO: 153/260 (epoch 5), train_loss = -1.795467495918, time/batch = 3.594885349274
2025-04-21 16:43:26,325:INFO: 154/260 (epoch 5), train_loss = -1.884036421776, time/batch = 5.267899274826
2025-04-21 16:43:35,291:INFO: 155/260 (epoch 5), train_loss = -1.981626987457, time/batch = 8.965077877045
2025-04-21 16:43:35,291:INFO: (epoch 5), loss = -0.050
2025-04-21 16:43:35,291:INFO: Best epoch 5, Best loss -0.05034431557242687
2025-04-21 16:43:35,291:INFO: Saving model
2025-04-21 16:43:39,894:INFO: 156/260 (epoch 6), train_loss = 3.248131275177, time/batch = 4.556813478470
2025-04-21 16:43:43,647:INFO: 157/260 (epoch 6), train_loss = 2.523586273193, time/batch = 3.752641677856
2025-04-21 16:43:44,053:INFO: 158/260 (epoch 6), train_loss = 2.876421689987, time/batch = 0.406634092331
2025-04-21 16:43:47,836:INFO: 159/260 (epoch 6), train_loss = 2.960462808609, time/batch = 3.782787561417
2025-04-21 16:43:56,572:INFO: 160/260 (epoch 6), train_loss = 2.764606475830, time/batch = 8.736011981964
2025-04-21 16:43:57,713:INFO: 161/260 (epoch 6), train_loss = -2.308656930923, time/batch = 1.141121864319
2025-04-21 16:44:01,746:INFO: 162/260 (epoch 6), train_loss = 2.547213792801, time/batch = 4.032392263412
2025-04-21 16:44:08,264:INFO: 163/260 (epoch 6), train_loss = 1.362741708755, time/batch = 6.517951965332
2025-04-21 16:44:17,819:INFO: 164/260 (epoch 6), train_loss = -2.253330469131, time/batch = 9.555203199387
2025-04-21 16:44:25,463:INFO: 165/260 (epoch 6), train_loss = -2.224283218384, time/batch = 7.643564224243
2025-04-21 16:44:28,760:INFO: 166/260 (epoch 6), train_loss = -2.312779903412, time/batch = 3.297985553741
2025-04-21 16:44:34,262:INFO: 167/260 (epoch 6), train_loss = -2.439972877502, time/batch = 5.501952171326
2025-04-21 16:44:42,642:INFO: 168/260 (epoch 6), train_loss = -2.506132125854, time/batch = 8.379144430161
2025-04-21 16:44:47,487:INFO: 169/260 (epoch 6), train_loss = 2.865682363510, time/batch = 4.845044136047
2025-04-21 16:44:51,144:INFO: 170/260 (epoch 6), train_loss = 5.723254680634, time/batch = 3.657649278641
2025-04-21 16:44:51,582:INFO: 171/260 (epoch 6), train_loss = 5.614681243896, time/batch = 0.437530040741
2025-04-21 16:44:55,536:INFO: 172/260 (epoch 6), train_loss = 5.209737777710, time/batch = 3.954452514648
2025-04-21 16:45:04,431:INFO: 173/260 (epoch 6), train_loss = 2.321174621582, time/batch = 8.894662141800
2025-04-21 16:45:05,556:INFO: 174/260 (epoch 6), train_loss = -2.615671873093, time/batch = 1.125078439713
2025-04-21 16:45:09,510:INFO: 175/260 (epoch 6), train_loss = 3.353177785873, time/batch = 3.954301595688
2025-04-21 16:45:16,170:INFO: 176/260 (epoch 6), train_loss = 1.658734798431, time/batch = 6.659223794937
2025-04-21 16:45:24,641:INFO: 177/260 (epoch 6), train_loss = -2.222254514694, time/batch = 8.471125125885
2025-04-21 16:45:32,159:INFO: 178/260 (epoch 6), train_loss = -2.104779243469, time/batch = 7.517880439758
2025-04-21 16:45:35,409:INFO: 179/260 (epoch 6), train_loss = -2.253361940384, time/batch = 3.250670671463
2025-04-21 16:45:40,786:INFO: 180/260 (epoch 6), train_loss = -2.470218181610, time/batch = 5.376740932465
2025-04-21 16:45:50,087:INFO: 181/260 (epoch 6), train_loss = -2.561738014221, time/batch = 9.300983905792
2025-04-21 16:45:50,087:INFO: (epoch 6), loss = 0.644
2025-04-21 16:45:50,087:INFO: Best epoch 5, Best loss -0.05034431557242687
2025-04-21 16:45:50,087:INFO: Saving model
2025-04-21 16:45:54,838:INFO: 182/260 (epoch 7), train_loss = 2.395341634750, time/batch = 4.719520092010
2025-04-21 16:45:58,464:INFO: 183/260 (epoch 7), train_loss = 6.131270408630, time/batch = 3.626630067825
2025-04-21 16:45:58,902:INFO: 184/260 (epoch 7), train_loss = 6.127615928650, time/batch = 0.437529563904
2025-04-21 16:46:02,841:INFO: 185/260 (epoch 7), train_loss = 6.106033802032, time/batch = 3.938664674759
2025-04-21 16:46:11,468:INFO: 186/260 (epoch 7), train_loss = 2.004462242126, time/batch = 8.627382755280
2025-04-21 16:46:12,530:INFO: 187/260 (epoch 7), train_loss = -2.820020437241, time/batch = 1.062572479248
2025-04-21 16:46:16,267:INFO: 188/260 (epoch 7), train_loss = 4.339525222778, time/batch = 3.736655473709
2025-04-21 16:46:22,441:INFO: 189/260 (epoch 7), train_loss = 2.348641157150, time/batch = 6.174032926559
2025-04-21 16:46:31,273:INFO: 190/260 (epoch 7), train_loss = -2.226359844208, time/batch = 8.831885576248
2025-04-21 16:46:39,135:INFO: 191/260 (epoch 7), train_loss = -2.012290716171, time/batch = 7.861817836761
2025-04-21 16:46:42,357:INFO: 192/260 (epoch 7), train_loss = -2.143366336823, time/batch = 3.222506523132
2025-04-21 16:46:47,624:INFO: 193/260 (epoch 7), train_loss = -2.493971586227, time/batch = 5.266516447067
2025-04-21 16:46:56,048:INFO: 194/260 (epoch 7), train_loss = -2.823887109756, time/batch = 8.424229621887
2025-04-21 16:47:00,502:INFO: 195/260 (epoch 7), train_loss = 2.015431165695, time/batch = 4.454329013824
2025-04-21 16:47:04,004:INFO: 196/260 (epoch 7), train_loss = 9.718375205994, time/batch = 3.501554489136
2025-04-21 16:47:04,410:INFO: 197/260 (epoch 7), train_loss = 10.218473434448, time/batch = 0.406293630600
2025-04-21 16:47:08,255:INFO: 198/260 (epoch 7), train_loss = 10.544354438782, time/batch = 3.844911098480
2025-04-21 16:47:17,188:INFO: 199/260 (epoch 7), train_loss = 1.427835464478, time/batch = 8.932508468628
2025-04-21 16:47:18,298:INFO: 200/260 (epoch 7), train_loss = -2.291138648987, time/batch = 1.110213041306
2025-04-21 16:47:22,144:INFO: 201/260 (epoch 7), train_loss = 7.315706729889, time/batch = 3.845815181732
2025-04-21 16:47:29,601:INFO: 202/260 (epoch 7), train_loss = 4.134814739227, time/batch = 7.457506418228
2025-04-21 16:47:38,135:INFO: 203/260 (epoch 7), train_loss = -2.809270381927, time/batch = 8.534214735031
2025-04-21 16:47:45,340:INFO: 204/260 (epoch 7), train_loss = -2.760744333267, time/batch = 7.204994201660
2025-04-21 16:47:48,436:INFO: 205/260 (epoch 7), train_loss = -2.798705339432, time/batch = 3.095945596695
2025-04-21 16:47:53,516:INFO: 206/260 (epoch 7), train_loss = -2.873323678970, time/batch = 5.079529523849
2025-04-21 16:48:02,349:INFO: 207/260 (epoch 7), train_loss = -2.908237695694, time/batch = 8.832607269287
2025-04-21 16:48:02,349:INFO: (epoch 7), loss = 1.687
2025-04-21 16:48:02,349:INFO: Best epoch 5, Best loss -0.05034431557242687
2025-04-21 16:48:02,349:INFO: Saving model
2025-04-21 16:48:06,896:INFO: 208/260 (epoch 8), train_loss = 1.544605970383, time/batch = 4.516387224197
2025-04-21 16:48:10,383:INFO: 209/260 (epoch 8), train_loss = 6.574754238129, time/batch = 3.487094163895
2025-04-21 16:48:10,790:INFO: 210/260 (epoch 8), train_loss = 5.718017578125, time/batch = 0.406275987625
2025-04-21 16:48:14,433:INFO: 211/260 (epoch 8), train_loss = 4.410125255585, time/batch = 3.642915964127
2025-04-21 16:48:22,935:INFO: 212/260 (epoch 8), train_loss = 0.976564586163, time/batch = 8.502852916718
2025-04-21 16:48:23,998:INFO: 213/260 (epoch 8), train_loss = -1.090416669846, time/batch = 1.062778949738
2025-04-21 16:48:27,640:INFO: 214/260 (epoch 8), train_loss = -0.415747910738, time/batch = 3.641716241837
2025-04-21 16:48:34,421:INFO: 215/260 (epoch 8), train_loss = -2.001719713211, time/batch = 6.781378507614
2025-04-21 16:48:43,553:INFO: 216/260 (epoch 8), train_loss = 4.081126213074, time/batch = 9.120495796204
2025-04-21 16:48:50,820:INFO: 217/260 (epoch 8), train_loss = 5.431147098541, time/batch = 7.267572402954
2025-04-21 16:48:53,947:INFO: 218/260 (epoch 8), train_loss = 5.180761337280, time/batch = 3.126205682755
2025-04-21 16:48:59,245:INFO: 219/260 (epoch 8), train_loss = 3.583739519119, time/batch = 5.298714160919
2025-04-21 16:49:07,232:INFO: 220/260 (epoch 8), train_loss = 1.152972221375, time/batch = 7.986874580383
2025-04-21 16:49:11,608:INFO: 221/260 (epoch 8), train_loss = 1.169854998589, time/batch = 4.376245260239
2025-04-21 16:49:15,283:INFO: 222/260 (epoch 8), train_loss = 0.877149820328, time/batch = 3.674103975296
2025-04-21 16:49:15,720:INFO: 223/260 (epoch 8), train_loss = 1.741328716278, time/batch = 0.437543869019
2025-04-21 16:49:19,347:INFO: 224/260 (epoch 8), train_loss = 1.989810466766, time/batch = 3.610943794250
2025-04-21 16:49:27,755:INFO: 225/260 (epoch 8), train_loss = 0.838903486729, time/batch = 8.408562183380
2025-04-21 16:49:28,757:INFO: 226/260 (epoch 8), train_loss = -2.673574686050, time/batch = 1.002208232880
2025-04-21 16:49:32,414:INFO: 227/260 (epoch 8), train_loss = 0.747181057930, time/batch = 3.656948328018
2025-04-21 16:49:38,463:INFO: 228/260 (epoch 8), train_loss = -0.515810072422, time/batch = 6.048643350601
2025-04-21 16:49:46,903:INFO: 229/260 (epoch 8), train_loss = -2.118892192841, time/batch = 8.440218210220
2025-04-21 16:49:54,233:INFO: 230/260 (epoch 8), train_loss = -1.978123188019, time/batch = 7.330056905746
2025-04-21 16:49:57,560:INFO: 231/260 (epoch 8), train_loss = -2.143261671066, time/batch = 3.327240705490
2025-04-21 16:50:03,392:INFO: 232/260 (epoch 8), train_loss = -2.492753744125, time/batch = 5.831105947495
2025-04-21 16:50:11,535:INFO: 233/260 (epoch 8), train_loss = -2.826058626175, time/batch = 8.143418788910
2025-04-21 16:50:11,535:INFO: (epoch 8), loss = 1.068
2025-04-21 16:50:11,551:INFO: Best epoch 5, Best loss -0.05034431557242687
2025-04-21 16:50:11,551:INFO: Saving model
2025-04-21 16:50:16,069:INFO: 234/260 (epoch 9), train_loss = 0.638513982296, time/batch = 4.487036943436
2025-04-21 16:50:19,462:INFO: 235/260 (epoch 9), train_loss = 4.977671623230, time/batch = 3.392859935760
2025-04-21 16:50:19,868:INFO: 236/260 (epoch 9), train_loss = 6.020692825317, time/batch = 0.406293153763
2025-04-21 16:50:23,650:INFO: 237/260 (epoch 9), train_loss = 6.407655239105, time/batch = 3.782357215881
2025-04-21 16:50:31,918:INFO: 238/260 (epoch 9), train_loss = 0.278958767653, time/batch = 8.267922878265
2025-04-21 16:50:32,950:INFO: 239/260 (epoch 9), train_loss = -2.007730960846, time/batch = 1.031319856644
2025-04-21 16:50:36,546:INFO: 240/260 (epoch 9), train_loss = 4.543365955353, time/batch = 3.596545219421
2025-04-21 16:50:42,740:INFO: 241/260 (epoch 9), train_loss = 2.234137296677, time/batch = 6.193481683731
2025-04-21 16:50:50,992:INFO: 242/260 (epoch 9), train_loss = -2.905178070068, time/batch = 8.252465009689
2025-04-21 16:50:58,216:INFO: 243/260 (epoch 9), train_loss = -2.791639804840, time/batch = 7.223370552063
2025-04-21 16:51:01,435:INFO: 244/260 (epoch 9), train_loss = -2.628616809845, time/batch = 3.219406366348
2025-04-21 16:51:06,921:INFO: 245/260 (epoch 9), train_loss = -2.716576099396, time/batch = 5.486310005188
2025-04-21 16:51:14,925:INFO: 246/260 (epoch 9), train_loss = -2.968157291412, time/batch = 8.003288984299
2025-04-21 16:51:19,161:INFO: 247/260 (epoch 9), train_loss = 1.879293799400, time/batch = 4.236137151718
2025-04-21 16:51:22,646:INFO: 248/260 (epoch 9), train_loss = 4.318296432495, time/batch = 3.485455989838
2025-04-21 16:51:23,115:INFO: 249/260 (epoch 9), train_loss = 4.134105682373, time/batch = 0.468781232834
2025-04-21 16:51:26,834:INFO: 250/260 (epoch 9), train_loss = 3.362608909607, time/batch = 3.719494104385
2025-04-21 16:51:35,024:INFO: 251/260 (epoch 9), train_loss = 0.015149191022, time/batch = 8.189919948578
2025-04-21 16:51:36,056:INFO: 252/260 (epoch 9), train_loss = -3.080304384232, time/batch = 1.031317234039
2025-04-21 16:51:39,713:INFO: 253/260 (epoch 9), train_loss = 0.899254977703, time/batch = 3.657379388809
2025-04-21 16:51:45,919:INFO: 254/260 (epoch 9), train_loss = -0.380180686712, time/batch = 6.206390142441
2025-04-21 16:51:55,700:INFO: 255/260 (epoch 9), train_loss = -2.678390741348, time/batch = 9.780733346939
2025-04-21 16:52:02,827:INFO: 256/260 (epoch 9), train_loss = -2.521733999252, time/batch = 7.127344369888
2025-04-21 16:52:06,531:INFO: 257/260 (epoch 9), train_loss = -2.639901638031, time/batch = 3.703278779984
2025-04-21 16:52:11,595:INFO: 258/260 (epoch 9), train_loss = -2.978030681610, time/batch = 5.064302206039
2025-04-21 16:52:19,663:INFO: 259/260 (epoch 9), train_loss = -3.161540031433, time/batch = 8.068133115768
2025-04-21 16:52:19,663:INFO: (epoch 9), loss = 0.240
2025-04-21 16:52:19,663:INFO: Best epoch 5, Best loss -0.05034431557242687
2025-04-21 16:52:19,663:INFO: Saving model
2025-04-21 16:52:19,710:INFO: Best epoch 5, Best loss -0.05034431557242687
